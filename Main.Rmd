---
title: "Proyecto de estad√≠stica: Etapa 3"
author: 
  - Sebasti√°n Rojas Vargas
  - Francisco Soto Quesada
  - Jairo Pacheco Campos
  - Jason Barrantes Rodr√≠guez
date: "10/06/2021"
output: word_document
---

# Lista de librer√≠as utilizadas

```{r setup, message=F, warning=F, echo = T, results = 'hide'}
library(visdat)
library(ggplot2)
library(DataExplorer)
library(datos)
library(EnvStats)
library(stests)
library("ggpubr")
library(stats)
library(BSDA)
library(PASWR2)
library(TeachingDemos)
library(mosaicData) # para usar KidsFeet
library(nortest) # para usar A-D, S-W, K-S-L test
library(fBasics) # para usar D‚ÄôAgostino-Pearson
library(moments) # para custoris y simetr√≠a
library(corrplot)
library(bbmle)
library(DALEX)
```

# I Parte: explicaci√≥n de los datos

A continuaci√≥n, se presenta una tabla con los principales aspectos del dataset utilizado.

**Dataset:** Diamantes

**Descripci√≥n general:** se opt√≥ por la utilizaci√≥n del dataset de diamantes del paquete de datos de R. El motivo de la elecci√≥n de este es que cuenta con una gran cantidad de datos y columnas. Estas √∫ltimas siendo de gran variedad entre datos cualitativos y cuantitativos. Adem√°s de todo esto el dataset cuenta con todas sus variables y sus datos ya traducidos al espa√±ol, facilitando as√≠ la comprensi√≥n de los datos.

**Filas:** 53 940

**Columnas:** 10

**Resumen del dataset:**

```{r}
str(diamantes)
```

**Resumen de los datos:**

```{r}
vis_dat(diamantes)
plot_missing(diamantes)
```

En esta √∫ltima imagen se puede observar que no hay datos faltantes en las columnas del dataset. Esto facilita los c√°lculos que se vean a realizar m√°s adelante ya que no hay necesidad de filtrar los datos faltantes.

## Resumen de variables seleccionadas

| Variables| Tipos| Descripci√≥n| Par√°metro por estimar (IC)|
|:--|:--|:--|:--|
| Precio| Cuantitativa| Precio en d√≥lares estadounidenses| Promedio usando distribuci√≥n z y distribuci√≥n t|
| Corte| Cualitativa| Calidad del corte (Regular, Bueno, Muy bueno, Premium, Ideal)| Proporci√≥n, diferencia de proporciones|
| Profundidad| Cuantitativa| Porcentaje de la profundidad total en mil√≠metros| Diferencia de promedios usando distribuci√≥n z y distribuci√≥n t|
| Quilates| Cuantitativa| Peso del diamante| Cociente de varianzas y varianza.

# II Parte: An√°lisis Inferencial (IC)

## IC de un promedio usando distribuci√≥n Z

A continuaci√≥n, se presentan los promedios usando distribuci√≥n normal est√°ndar de una poblaci√≥n de datos extra√≠dos del dataset diamantes, utilizando los siguientes datos de la variable precio del dataset de diamantes:

```{r}
set.seed(4562) # semilla

poblacion <- as.data.frame(diamantes)
poblacion.precios <- poblacion$precio

n1 <- length(poblacion.precios)
mu1 <- mean(poblacion.precios)
var1 <- var(poblacion.precios)

```

| Muestra| Tama√±o| Promedio| Varianza|
|:--|:--|:--|:--|
| A| `r n1`| `r mu1`| `r var1`|

**Hip√≥tesis asumidas** 

Dado que la muestra es mayor a 30 se puede asumir que la distribuci√≥n muestral de medias sigue una distribuci√≥n normal y que se puede aproximar œÉ‚ÇÅ mediante s‚ÇÅ.

**C√°lculo**

Conociendo los datos se puede aproximar el IC utilizando la funci√≥n z.test de las librer√≠as stests BSDA y PASWR2.


Para stests los par√°metros son los siguientes:

* **x:** vector num√©rico que representa la muestra
* **sigma2:** varianza de la muestra
* **conf.level:** nivel de confidencia (opcional, se asume 0.95 por defecto)

```{r}
stests::z.test(
  x = poblacion.precios, 
  sigma2 = var(poblacion.precios), 
  conf.level = 0.95
  )$conf.int
```


Los par√°metros tanto para BSDA y PASWR2 son los siguientes:

* **x:** la muestra
* **sigma.x:** desviaci√≥n est√°ndar de la muestra
* **conf.level:** nivel de confidencia (opcional, se asume 0.95 por defecto)

```{r}
BSDA::z.test(
  x = poblacion.precios, 
  sigma.x = sqrt(var(poblacion.precios)), 
  conf.level = 0.95
  )$conf.int
```
```{r}
IC <- PASWR2::z.test(
  x = poblacion.precios, 
  sigma.x = sqrt(var(poblacion.precios)), 
  conf.level = 0.95
  )$conf.int

IC
```

**Conclusiones**

De los resultados obtenidos se puede concluir que la media de precios del dataset diamante se encuentra en el intervalo ]`r IC`[ con un 95% de confianza, resultado que coincide en las tres librer√≠as utilizadas.

## IC de un promedio usando distribuci√≥n t
A continuaci√≥n, se presentan los promedios usando distribuci√≥n t de una poblaci√≥n, utilizando muestras de la variable precio del dataset de diamantes.

```{r}
## Se toman filas random para sacar del dataset
set.seed(6894)
filas.random <- sample(1:53940, 20, replace= T)

## Se generan datasets nuevos con las filas random anteriores 
muestra1 <- as.data.frame(diamantes[filas.random,])
muestra.precios <- muestra1$precio
n1 <- length(muestra.precios)
mu1 <- mean(muestra.precios)
de1 <- sqrt(var(muestra.precios))
alpha1 <- 0.05

```

| Muestra| Tama√±o| Promedio| Desviaci√≥n est√°ndar|
|:--|:--|:--|:--|
| A| `r n1`| `r mu1`| `r de1`|

En este caso dado que el tama√±o de la muestra es menor a 30 se ha optado por realizar una inspecci√≥n visual de los datos para ver si se asemeja a una distribuci√≥n normal.

```{r echo=FALSE}
ggdensity(muestra1$profundidad, 
          main = "Gr√°fico de densidad de la profundidad de la muestra A",
          xlab = "Precio de los diamantes")
```

**Hip√≥tesis asumidas**

Como se puede observar, la muestra tiene forma de campana, por lo que se puede asumir que sigue una distribuci√≥n normal. 

**C√°lculo**

Conociendo esto se puede aproximar el IC mediante la funci√≥n t.test, la cual tiene la siguiente estructura, con los siguientes par√°metros:

* **x:** muestra
* **conf.level:** nivel de confidencia

```{r}
IC <- t.test(
  x = muestra.precios,
  conf.level = 0.95
  )$conf.int

IC
```

**Conclusi√≥n**

De los resultados obtenidos, se puede concluir que la media de precios del dataset de diamantes se encuentra en el intervalo ]`r IC`[ con un 95% de confianza. Adem√°s de esto, compar√°ndolo con el IC de la distribuci√≥n Z se puede observar que este posee menor precisi√≥n debido a la poca cantidad de datos que fueron brindados.

## IC de una proporci√≥n

A continuaci√≥n, se presenta la proporci√≥n para una poblaci√≥n de datos tomados del dataset diamantes, para ello se ha utilizado una muestra de la variable "corte" donde se incluyen todos los diamantes cuyo corte sea de tipo "Premium" o "Ideal", utilizando una muestra de gama alta de la siguiente manera:

```{r}
gamaAlta <- diamantes[diamantes$corte == "Premium" | diamantes$corte == "Ideal",]
length(gamaAlta$corte)
```

| Gama| Corte| Tama√±o de muestra|
|:--|:--|:--|
| Alta| Premium e Ideal| `r length(gamaAlta$corte)`| 

Como sabemos el dataset diamantes contiene una variable llamada corte, de igual manera, este dataset contiene otra variable llamada color. Estas variables las utilizaremos para saber cu√°l es la proporci√≥n que existe de un diamante de corte premium o ideal que hemos llamado gama alta con respecto al color que este posee. Para ello utilizamos la poblaci√≥n de diamantes de gama alta que sean de color tipo D:

```{r}
exitos.alta <- gamaAlta[gamaAlta$color == "D",]
length(exitos.alta$color)
```

| Color| Tama√±o de muestra|
|:--|:--|
| D| `r length(exitos.alta$color)`| 

**Hip√≥tesis asumidas**

Antes de realizar las operaciones se debe verificar que np > 5 y nq > 5

Para ello tenemos los siguientes datos:

$$p = \frac{x}{n} = \frac{4437}{35342} = 0.1255446777$$
$$np = 35342 * 0.1255446777 = 4437$$
$$q = 1-p = 1 - 0.1255446777 = 0.8744553223$$
$$nq = 35342 * 0.8744553223 = 30905$$
                                        
Como ambos valores son mayores a 5 es posible obtener la proporci√≥n. Una vez conocidos estos datos se puede calcular el IC de la proporci√≥n, para esto se implementa la funci√≥n prop.test para una poblaci√≥n de la siguiente manera:

**C√°lculo**

Una vez conociendo todos los datos, se procede a calcular el intervalo de confianza para una proporci√≥n con un nivel de confianza del 95%:

```{r}
prop.test(x=length(exitos.alta$color), n=length(gamaAlta$corte), conf.level = 0.95)$conf.int
```

En donde:

* **x:** vector con el conteo de √©xitos de la muestra
* **n:** vector con el n√∫mero de ensayos la muestra
* **conf.level:** nivel de confianza

**Conclusiones**

De los resultados obtenidos se puede observar que el intervalo resultante es muy peque√±o, esto debido a la gran cantidad de datos que se usaron para realizar el c√°lculo.

## IC de una diferencia de proporciones

A continuaci√≥n, se presenta la diferencia de proporciones para dos poblaciones de datos tomados del dataset diamantes, para ello se han utilizado dos muestras de la variable "corte" donde en la primera se incluyen todos los diamantes cuyo corte sea de tipo "Premium" √≥ "Ideal" (muestra de gama alta) y la segunda muestra donde se incluyen todos los diamantes cuyo corte sea de tipo "Regular" √≥  "Bueno" (muestra de gama baja), de la siguiente manera:

```{r}
gamaAlta <- diamantes[diamantes$corte == "Premium" | diamantes$corte == "Ideal",]
length(gamaAlta$corte)
gamaBaja <- diamantes[diamantes$corte == "Regular" | diamantes$corte == "Bueno",]
length(gamaBaja$corte)

exitos.alta <- gamaAlta[gamaAlta$color == "D",]
length(exitos.alta$color)
exitos.baja <- gamaBaja[gamaBaja$color == "D",]
length(exitos.baja$color)
```

| Gama| Corte| Tama√±o de muestra|
|:--|:--|:--|
| Alta| Premium e Ideal| `r length(gamaAlta$corte)`|
| Baja| Regular y Bueno| `r length(gamaBaja$corte)`| 

Como sabemos el dataset diamantes contiene una variable llamada corte, de igual manera, este dataset contiene otra variable llamada color. Estas variables las utilizaremos para saber cu√°l es la diferencia de proporciones que existen de un diamante de gama alta y de gama baja con respecto al color que este posee. Para ello utilizamos la poblaci√≥n de diamantes de gama alta y baja que sean de color tipo D para representar los √©xitos:

| Gama | Color| Tama√±o de muestra|
|:--|:--|:--|
| Alta| D| `r length(exitos.alta$color)`|
| Baja| D| `r length(exitos.baja$color)`| 

**Hip√≥tesis asumidas**

Antes de realizar las operaciones se debe verificar que np > 5 y nq > 5 para las dos poblaciones

Para ello tenemos los siguientes datos para la primera poblaci√≥n: 

$$p_{1} = \frac{x_{1}}{n_{1}} = \frac{4437}{35342} = 0.1255446777$$
$$n_{1}p_{1} = 35342 * 0.1255446777 = 4437$$
$$q_{1} = 1-p_{1} = 1 - 0.1255446777 = 0.8744553223$$
$$n_{1}q_{1} = 35342 * 0.8744553223 = 30905$$

Y tenemos los siguientes datos para la segunda poblaci√≥n: 

$$p_{2} = \frac{x_{2}}{n_{2}} = \frac{825}{6516} = 0.126611418$$
$$n_{2}p_{2} = 6516 * 0.126611418 = 825$$
$$q_{2} = 1-p_{2} = 1 - 0.126611418 = 0.873388582$$
$$n_{2}q_{2} = 6516 * 0.873388582 = 5691$$
  
                                        
Como ambos valores son mayores a 5 significa que si se puede realizar la diferencia de proporciones. Una vez conocidos estos datos se puede calcular el IC para la diferencia de proporciones, para esto se implementa la funci√≥n prop.test para dos poblaciones de la siguiente manera:


```{r}
prop.test(x = c(length(exitos.alta$color) , length(exitos.baja$color)), n = c(length(gamaBaja$corte), length(gamaAlta$corte)), conf.level = 0.95)$conf.int
```

En donde:

* **x:** vector con el conteo de √©xitos de la muestra
* **n:** vector con el n√∫mero de ensayos la muestra
* **conf.level:** nivel de confianza

De la cual se puede concluir que la proporci√≥n de la muestra A es mayor que el de la muestra B.

## IC de una diferencia de promedios usando distribuci√≥n z

Para este ejemplo se utilizar√°n dos grupos. En primer lugar, est√° el grupo de diamantes que se considera que tienen un color de buena calidad, este grupo est√° compuesto de aquellos diamantes cuyo color es "D", "E" o "F". Luego se tiene el grupo diamantes cuyo color es de peor calidad, el cual est√° compuesto por los diamantes con colores "H", "I" o "J". Ambos grupos est√°n distribuidos de la siguiente manera:

```{r}
buenaCalidad <- diamantes[diamantes$color == "D" | diamantes$color == "E" | diamantes$color == "F",]
peorCalidad <- diamantes[diamantes$color == "H" | diamantes$color == "I" | diamantes$color == "J",]

length(buenaCalidad$color)
length(peorCalidad$color)
```

| Calidad| Colores| Tama√±o de muestra|
|:--|:--|:--|
| Buena| D, E o F| `r length(buenaCalidad$color)`|
| Peor| H, I o J| `r length(peorCalidad$color)`|

**Hip√≥tesis asumidas**

Dado que ambas muestras son mayores a 30 se puede asumir que la distribuci√≥n muestral de medias sigue una distribuci√≥n normal y se puede aproximar œÉ‚ÇÅ y œÉ‚ÇÇ mediante s‚ÇÅ  y s‚ÇÇ.

**C√°lculo**

Una vez obtenidos estos datos se desea calcular la diferencia de promedios de profundidad entre la poblaci√≥n de buena calidad y la de peor calidad con un intervalo de confianza del 95%. Para esto se hace uso de las siguientes funciones:

```{r}
BSDA::z.test(x = buenaCalidad$profundidad, y = peorCalidad$profundidad, sigma.x = sd(buenaCalidad$profundidad), sigma.y = sd(peorCalidad$profundidad), conf.level = 0.95)$conf.int
PASWR2::z.test(x = buenaCalidad$profundidad, y = peorCalidad$profundidad, sigma.x = sd(buenaCalidad$profundidad), sigma.y = sd(peorCalidad$profundidad), conf.level = 0.95)$conf.int
```

Ambas funciones aplican para una y dos poblaciones y est√°n compuestas de los siguientes par√°metros, en donde:

* **x:** vector num√©rico que representa la primera muestra
* **y:** vector num√©rico que representa la segunda muestra (opcional)
* **sigma.x:** desviaci√≥n est√°ndar de x (opcional)
* **sigma.y:** desviaci√≥n est√°ndar de y (opcional)
* **conf.level:** nivel de confianza entre 0 y 1 (opcional, se asume 0.95 por defecto)

**Conclusiones**

De los resultados obtenidos para la diferencia de promedios se puede concluir que la media de profundidad de diamantes con colores de baja calidad es mayor que la diamantes con colores de alta calidad.

## IC de una diferencia de promedios usando distribuci√≥n t

Para este caso se utilizar√°n muestras aleatorias sin reemplazo de tama√±o 25 de los dos grupos utilizados en el c√°lculo anterior (diamantes con color de buena calidad y diamantes con color de peor calidad).

```{r}
# Se sacan los datos de la calidad
buenaCalidad <- diamantes[diamantes$color == "D" | diamantes$color == "E" | diamantes$color == "F",]
peorCalidad <- diamantes[diamantes$color == "H" | diamantes$color == "I" | diamantes$color == "J",]

# Se toman las filas para las muestras aleatorias
set.seed(6894)
filas.randomMejorCalidad <- sample(1:length(buenaCalidad$color), 25, replace= F)
filas.randomPeorCalidad <- sample(1:length(peorCalidad$color), 25, replace= F)

muestraMejorCalidad <- as.data.frame(buenaCalidad[filas.randomMejorCalidad,])
muestraPeorCalidad <- as.data.frame(peorCalidad[filas.randomPeorCalidad,])

length(muestraMejorCalidad$color)
length(muestraPeorCalidad$color)
```

| Calidad| Colores| Tama√±o de muestra|
|:--|:--|:--|
| Buena| D, E o F| `r length(muestraMejorCalidad$color)`|
| Peor| H, I o J| `r length(muestraPeorCalidad$color)`|

En este caso dado que los tama√±os de las muestras son menores a 30 se ha optado por realizar una inspecci√≥n visual de los datos para ver si se asemejan a una distribuci√≥n normal

```{r echo=FALSE}
ggdensity(muestraMejorCalidad$profundidad, 
          main = "Gr√°fico de densidad de la profundidad de la muestra A",
          xlab = "Profundidad de los diamantes")
```

```{r echo=FALSE}
ggdensity(muestraPeorCalidad$profundidad, 
          main = "Gr√°fico de densidad de la profundidad de la muestra B",
          xlab = "Profundidad de los diamantes")
```

**Hip√≥tesis asumidas**

Como se puede observar ambas muestras tienen forma de campana, por lo que se puede asumir que siguen una distribuci√≥n normal. Adem√°s, tambi√©n se asume que las varianzas son iguales. Sin embargo, como las muestras son peque√±as no se pueden utilizar s‚ÇÅ  y s‚ÇÇ para realizar una aproximaci√≥n œÉ‚ÇÅ y œÉ‚ÇÇ.

**C√°lculo**

Una vez obtenidos estos datos se desea calcular la diferencia de promedios de profundidad entre las muestras de buena calidad y las de peor calidad con un intervalo de confianza del 95%. Para esto se hace uso de la siguiente funci√≥n:

```{r}
t.test(x=muestraMejorCalidad$profundidad, y=muestraPeorCalidad$profundidad, conf.level = 0.95, var.equal = TRUE)$conf.int
```

Donde:

* **x:** primera muestra
* **y:** segunda muestra
* **conf.level:** nivel de confidencia
* **var.equal:** si las varianzas se asumen iguales

**Conclusi√≥n**

A diferencia del caso anterior, dado a que las muestras aqu√≠ son m√°s peque√±as, se puede observar que hay tanto valores negativos como positivos, por lo cual no se puede llegar a una conclusi√≥n con certeza ya que existe la posibilidad de que ambas muestras sean iguales o que una sea mayor que otra.

## IC de una varianza
A continuaci√≥n, se presenta IC de la varianza de la variable quilates del dataset diamantes.

| Muestra| Tama√±o|
|:--|:--|
| A| `r length(diamantes$quilate)`|

Una vez tenemos la muestra, utilizaremos la variable de quilates para obtener el IC de varianza de la muestra, para esto utilizaremos la librer√≠a EnvStats y espec√≠ficamente su m√©todo varTest que nos dar√° el intervalo que estamos buscando.

Antes de realizar el c√°lculo debemos tener en cuenta lo siguiente:

* El nivel de confianza utilizado ser√° de 95%
* La muestra sigue una distribuci√≥n normal

**C√°lculo**

El c√≥digo utilizado para este c√°lculo fue:

```{r}
P1 <- varTest(diamantes$quilate, conf.level = 0.95)$conf.int
P1
```

Donde:

* **Primer par√°metro:** primera muestra
* **conf.level:** nivel de confidencia

**Conclusi√≥n**

Dando como resultado el IC del 95% para la varianza de quilates:
]`r P1`[, como podemos ver el intervalo es muy peque√±o y esto se debe a que se usaron una gran cantidad de datos para realizar el c√°lculo, dando un resultado muy preciso.


## IC de un cociente de varianzas

Gracias a la librer√≠a stests podemos realizar el cociente de varianza de dos poblaciones, para esto dividiremos el dataset de diamantes de dos poblaciones la primera contendr√° los diamantes que tengan una alta claridad, teniendo como la m√°s baja calidad posible para esta poblaci√≥n VS1 y una segunda poblaci√≥n que estar√° compuesta por los diamantes que tengan una claridad igual o inferior a VS2.


```{r}
claridadAlta <- diamantes[diamantes$claridad == "IF" | diamantes$claridad == "VVS1" | diamantes$claridad == "VVS2" |
diamantes$claridad == "VS1",]
length(claridadAlta$quilate)

clariadadBaja <- diamantes[diamantes$claridad == "VS2" | diamantes$claridad == "SI1" | diamantes$claridad == "SI2" | 
diamantes$claridad == "I1",]
length(clariadadBaja$quilate)
```

| Calidad| Claridad| Tama√±o de muestra|
|:--|:--|:--|
| Alta| IF, VVSS1, VVSS2, VS1| `r length(claridadAlta$claridad)`|
| Baja| VS2, SI1, SI2, I1| `r length(clariadadBaja$claridad)`|


Antes de realizar el c√°lculo debemos tener en cuenta lo siguiente:

* El nivel de confianza utilizado ser√° de 95%.
* La poblaci√≥n 1 y la poblaci√≥n 2 se comportan normalmente.

**C√°lculo**

El c√≥digo utilizado para este c√°lculo fue:

```{r}
R <- stests :: var.test(claridadAlta$quilate, clariadadBaja$quilate,conf.level = 0.95)$conf.int
R
```

Donde:

* **Primer par√°metro:** primera muestra
* **Segundo par√°metro:** segunda muestra
* **conf.level:** nivel de confidencia

**Conclusi√≥n**

Dando como resultado:
]`r R`[

En conclusi√≥n, al resultado obtenido podemos ver que las varianzas de estas dos poblaciones no deber√≠an ser iguales ya que el n√∫mero 1 no pertenece al intervalo, tambi√©n podemos decir que la varianza de la segunda poblaci√≥n es mayor ya que ambos valores son menores que 1.

# III Parte: An√°lisis Inferencial (pruebas de hip√≥tesis de una y dos poblaciones)

## Resumen de variables seleccionadas

**Una poblaci√≥n:**

| Variables| Tipos| Descripci√≥n| Par√°metro por estimar (IC)|
|:--|:--|:--|:--|
| Precio| Cuantitativa| Precio en d√≥lares estadounidenses| Promedio usando distribuci√≥n z y distribuci√≥n t|
| Corte| Cualitativa| Calidad del corte (Regular, Bueno, Muy bueno, Premium, Ideal)| Proporci√≥n |
| Quilates| Cuantitativa| Peso del diamante| Varianza

**Dos poblaciones:**

| Variables| Tipos| Descripci√≥n| Par√°metro por estimar (IC)|
|:--|:--|:--|:--|
| Corte| Cualitativa| Calidad del corte (Regular, Bueno, Muy bueno, Premium, Ideal)| Diferencia de proporciones|
| Profundidad| Cuantitativa| Porcentaje de la profundidad total en mil√≠metros| Diferencia de promedios usando distribuci√≥n z y t y cociente de varianzas|

## Prueba de hip√≥tesis para un promedio usando distribuci√≥n Z

Para este ejemplo se utilizar√°n dos grupos (los mismos utilizados para la prueba del IC para un promedio usando distribuci√≥n Z). Utilizando todos los datos de la variable precio extra√≠dos del dataset diamantes. Tal est√° distribuido de la siguiente manera:

```{r}
set.seed(4562) # semilla

poblacion <- as.data.frame(diamantes)
poblacion.precios <- poblacion$precio

n1 <- length(poblacion.precios)
mu1 <- mean(poblacion.precios)
var1 <- var(poblacion.precios)

n1
```

| Muestra| Tama√±o| Promedio| Varianza|
|:--|:--|:--|:--|
| A| `r n1`| `r mu1`| `r var1`|

**Hip√≥tesis asumidas**

Dado que la muestra es mayor a 30, debido a las condiciones del teorema del l√≠mite central, se puede asumir que la poblaci√≥n sigue una distribuci√≥n normal y que se puede aproximar œÉ‚ÇÅ mediante s‚ÇÅ.


**C√°lculo**

Sea:

* $\mu_{p}$: la media del precio de los diamantes

Y dadas las siguientes hip√≥tesis para la prueba:

* $H_{0}: \mu_{p} = 4000$
* $H_{1}: \mu_{p} > 4000$

Una vez obtenidos estos datos se procede a realizar la prueba de hip√≥tesis haciendo uso de las siguientes funciones:

```{r}
stests::z.test(
  x = poblacion.precios, 
  sigma2 = var(poblacion.precios), 
  mu = 4000, alternative = "greater"
)

BSDA::z.test(
  x = poblacion.precios, 
  sigma.x = sd(poblacion.precios), 
  mu = 4000, alternative = "greater"
)

PASWR2::z.test(
  x = poblacion.precios, 
  sigma.x = sd(poblacion.precios), 
  mu = 4000, alternative = "greater"
)

```

Las funciones BSDA y PASWR2 aplican para una y dos poblaciones y est√°n compuestas de los siguientes par√°metros, en donde:

* **x:** vector num√©rico que representa la primera muestra
* **sigma.x:** desviaci√≥n est√°ndar de x (opcional)
* **mu:** el valor de la media o la diferencia de medias en la hip√≥tesis nula
* **alternative:** indica si la prueba es de cola izquierda (less), derecha (greater) o de dos colas (two.sided)

En cambio, las funciones de stests solo aplican para una poblaci√≥n, la cual cuenta con los par√°metros donde:

* **x:** vector num√©rico que representa la primera muestra
* **sigma2:** varianza de x (opcional)
* **mu:** el valor de la media o la diferencia de medias en la hip√≥tesis nula
* **alternative:** indica si la prueba es de cola izquierda (less), derecha (greater) o de dos colas (two.sided)

**Resumen de la prueba**

| Dato| Valor|
|:--|:--|
| Valor observado| $z_{obs}=-3.9121$|
| Grados de libertad| No corresponde|
| Estad√≠stico de prueba| $\tilde{x}_p=4000$|
| Regi√≥n de aceptaci√≥n| ]3904.545, $+\infty$[|
| Regi√≥n de rechazo| ]$-\infty$, 3904.545[|
| Nivel de confianza| 95%|

**Conclusi√≥n**

No se encontr√≥ evidencia en contra $H_{0}$ por lo cual se puede asumir que la media de los precios de diamantes es menor o igual a 4000 d√≥lares estadounidenses. Esto concordando tambi√©n con los resultados del valor P, donde se tiene una aceptaci√≥n fuerte de $H_{0}$.

## Prueba de hip√≥tesis para un promedio usando distribuci√≥n t

Para este caso se utilizar√°n muestras las mismas muestras del caso anterior (precio de los diamantes), pero esta vez con una muestra de 20 datos.

```{r}
## Se toman filas random para sacar del dataset
set.seed(6894)
filas.random <- sample(1:53940, 20, replace= T)

## Se generan datasets nuevos con las filas random anteriores 
muestra1 <- as.data.frame(diamantes[filas.random,])
muestra.precios <- muestra1$precio
n1 <- length(muestra.precios)
mu1 <- mean(muestra.precios)
de1 <- sqrt(var(muestra.precios))
alpha1 <- 0.05

```

| Muestra| Tama√±o| Promedio| Desviaci√≥n est√°ndar|
|:--|:--|:--|:--|
| A| `r n1`| `r mu1`| `r de1`|

En este caso dado que el tama√±o de la muestra es menor a 30 se ha optado por realizar una inspecci√≥n visual de los datos para ver si se asemeja a una distribuci√≥n normal.

```{r echo=FALSE}
ggdensity(muestra1$profundidad, 
          main = "Gr√°fico de densidad de la profundidad de la muestra A",
          xlab = "Precio de los diamantes")
```

**Hip√≥tesis asumidas**

Como se puede observar, la muestra tiene forma de campana, por lo que se puede asumir que sigue una distribuci√≥n normal. 

**C√°lculo**

Sea:

* $\mu_{p}$: la media del precio de los diamantes

Y dadas las siguientes hip√≥tesis para la prueba:

* $H_{0}: \mu_{p} = 4000$
* $H_{1}: \mu_{p} > 4000$

Una vez obtenidos estos datos se procede a realizar la prueba de hip√≥tesis haciendo uso de la siguiente funci√≥n:


```{r}
t.test(
  x = muestra.precios, 
  mu = 4000, alternative = "greater"
  )
```

La funci√≥n est√° compuesta de los siguientes par√°metros, en donde:

* **x:** vector num√©rico que representa la primera muestra
* **mu:** el valor de la media o la diferencia de medias en la hip√≥tesis nula
* **alternative:** indica si la prueba es de cola izquierda (less), derecha (greater) o de dos colas (two.sided)

**Resumen de la prueba**

| Dato| Valor|
|:--|:--|
| Valor observado| $t_{obs}=0.55392$|
| Grados de libertad| $v=19$|
| Estad√≠stico de prueba| $\tilde{x}_t=4000$|
| Regi√≥n de aceptaci√≥n| ]2664.219, $+\infty$[|
| Regi√≥n de rechazo| ]$-\infty$, 2664.219[|
| Nivel de confianza| 95%|


**Conclusi√≥n**

No se encontr√≥ evidencia en contra $H_{0}$ por lo cual se puede asumir que la media del precio de los diamantes es menor o igual a 4000 d√≥lares estadounidenses. Esto concordando tambi√©n con los resultados del valor P, donde se tiene una aceptaci√≥n de $H_{0}$.



## Prueba de hip√≥tesis para una proporci√≥n

```{r include=FALSE}
library(datos)
library(stats)




gamaAlta <- diamantes[diamantes$corte == "Premium" | diamantes$corte == "Ideal",]
tama√±oMuestraGama <- length(gamaAlta$corte)


exitos.alta <- gamaAlta[gamaAlta$color == "D",]
tama√±oMuestraColor <-length(exitos.alta$color)



prop.test(x=length(exitos.alta$color), n=length(gamaAlta$corte), p = 0.12, alternative = "less", conf.level = 0.95)

```

Basado en la experiencia, un joyero afirma que m√≠nimo el 12% de los diamantes de gama alta son de color tipo D.

¬øPodemos aceptar la afirmaci√≥n del joyero?

Para realizar la prueba, se consideran las siguientes hip√≥tesis:

\(H_{0}:p =0.12(\geq )\)

\(H_{1}:p < 0.12\)

d√≥nde p representa la proporci√≥n de que unos diamantes de gama alta elegidos al azar, sean de color tipo D. La prueba a realizar es de cola izquierda.

En R se est√° implementado la funci√≥n prop.test, que adem√°s tambi√©n sirve para contrastar dos proporciones por medio de muestras independientes grandes.

Su sintaxis es:

              prop.test(x, n, p = ..., alternative = ..., conf.level = ...)

donde:

* **n** es el tama√±o de la muestra.
* **x** es el n√∫mero de √©xitos de la muestra.
* **p** es la proporci√≥n poblacional que contrastamos.
* **alternative** especifica la hip√≥tesis alternativa, debe ser "two.sided", "greater" o "less". 
* **conf.level** es el nivel de confianza.

Para obtener el valor n se tomaron los datos del dataset "Diamantes" donde se utiliz√≥ una muestra de la variable "corte" incluy√©ndose todos los diamantes cuyo corte sea de tipo "Premium" o "Ideal", siendo esta una muestra de diamantes de gama alta, de la siguiente manera:


```{r}
gamaAlta <- diamantes[diamantes$corte == "Premium" | diamantes$corte == "Ideal",]
gamaAlta
tama√±oMuestraGama <- length(gamaAlta$corte)
tama√±oMuestraGama

```

| Gama| Corte| Tama√±o de muestra|
|:--|:--|:--|
| Alta| Premium e Ideal| `r tama√±oMuestraGama`| 



Para obtener el valor x se incorpor√≥ la variable color del dataset "Diamantes" para saber cu√°l es el n√∫mero de diamantes que hay de corte "premium" o "Ideal" (que hemos llamado gama alta) de color tipo D, de la siguiente manera:

```{r}
exitos.alta <- gamaAlta[gamaAlta$color == "D",]
exitos.alta
tama√±oMuestraColor <-length(exitos.alta$color)
tama√±oMuestraColor
```

| Gama| Corte| Color| Tama√±o de muestra|
|:--|:--|:--|:--|
| Alta| Premiun e Ideal | D| `r tama√±oMuestraColor`| 


Antes de realizar las operaciones se debe verificar que np > 5 y nq > 5

Para ello tenemos los siguientes datos:

p = x/n = 4437/35342 = 0.1255446777

np = 35342 * 0.1255446777 = 4437
                                        
q = 1-p = 1 - 0.1255446777 = 0.8744553223
                                        
nq = 35342 * 0.8744553223 = 30905

                                        
Como ambos valores son mayores a 5 se procede a utilizar la funci√≥n prop.test con sus respectivos valores
```{r}
prop.test(x=length(exitos.alta$color), n=length(gamaAlta$corte), p = 0.12, alternative = "less", conf.level = 0.95)
```


**Resumen de la prueba**

| Dato| Valor|
|:--|:--|
| Valor observado| $z_{obs}$ = 3.199531216|
| Grados de libertad| no corresponde|
| Estad√≠stico de prueba| $\tilde{p}$ = 0.1255447|
| Regi√≥n de aceptaci√≥n| ]0.0000000, 0.1284867[|
| Regi√≥n de rechazo| ]0.1284867, 1[|
| Nivel de confianza| 0.95|


**Conclusi√≥n:**

\(H_{0}\) no puede ser rechazado dado que no se encontr√≥ evidencia suficiente en contra, ya que seg√∫n lo observado el 0.12 se encuentra dentro del intervalo de aceptaci√≥n y el valor p es mayor que el valor de alfa, por lo que lo ubica en la regi√≥n de aceptaci√≥n, y por ende se asume como v√°lida la afirmaci√≥n del joyero.  

## Prueba de hip√≥tesis para una diferencia de proporciones

```{r include=FALSE}
library(datos)
library(stats)




gamaBaja <- diamantes[diamantes$corte == "Regular" | diamantes$corte == "Bueno",]
gamaBaja

gamaAlta <- diamantes[diamantes$corte == "Premium" | diamantes$corte == "Ideal",]
gamaAlta



tama√±oMGB <- length(gamaBaja$corte)
tama√±oMGA <- length(gamaAlta$corte)



exitos.baja <- gamaBaja[gamaBaja$color == "D",]
exitosBaja <- length(exitos.baja$color) 

exitos.alta <- gamaAlta[gamaAlta$color == "D",]
exitosAlta <- length(exitos.alta$color)




prop.test(x = c(length(exitos.alta$color) , length(exitos.baja$color)), n = c(length(gamaAlta$corte), length(gamaBaja$corte)))
```


Para las pruebas de contraste de proporciones para muestras grandes, se utilizar√° la funci√≥n prop.test

Su sintaxis es:

              prop.test(x, n, p = ..., alternative = ..., conf.level = ...)

donde:

* **n** es un vector de dos entradas de los respectivos tama√±os de las muestras.
* **x** es el vector de dos n√∫meros naturales que representan los √©xitos ambas muestras.


Es este ejercicio se contrastar√° si la proporci√≥n de diamantes de gama alta de color tipo D es la misma que la proporci√≥n de diamantes de gama baja de color tipo D

Para realizar esta prueba, se considerar√°n las siguientes hip√≥tesis:

\(H_{0}:p_{a}-p_{b} = 0\)

\(H_{1}:p_{a}-p_{b} \neq 0\)


Para obtener el valor n se tomaron dos muestras de la variable "corte", en la primera muestra se incluyen todos los diamantes cuyo corte sea de tipo "Premium" √≥ "Ideal" (muestra de gama alta) y la segunda muestra donde se incluyen todos los diamantes cuyo corte sea de tipo "Regular" √≥  "Bueno" (muestra de gama baja), de la siguiente manera:


```{r}
gamaAlta <- diamantes[diamantes$corte == "Premium" | diamantes$corte == "Ideal",]
gamaAlta

gamaBaja <- diamantes[diamantes$corte == "Regular" | diamantes$corte == "Bueno",]
gamaBaja

tama√±oMGA <- length(gamaAlta$corte)
tama√±oMGA

tama√±oMGB <- length(gamaBaja$corte)
tama√±oMGB

```


| Gama| Corte| Tama√±o de muestra|
|:--|:--|:--|
| Alta| Premium e Ideal| `r tama√±oMGA`| 


| Gama| Corte| Tama√±o de muestra|
|:--|:--|:--|
| Baja| Regular y Bueno| `r tama√±oMGB`| 



Para obtener el valor x se incorpor√≥ la variable color del dataset "Diamantes", con el fin de calcular cuantos diamantes de gama alta y baja son de color tipo D, de la siguiente manera:

```{r}
exitos.alta <- gamaAlta[gamaAlta$color == "D",]
exitos.alta

exitos.baja <- gamaBaja[gamaBaja$color == "D",]
exitos.baja


exitosAlta <- length(exitos.alta$color)
exitosAlta

exitosBaja <- length(exitos.baja$color) 
exitosBaja
```

| Gama | Color| Tama√±o de muestra|
|:--|:--|:--|
| Alta| D| `r exitosAlta`| 

| Gama | Color| Tama√±o de muestra|
|:--|:--|:--|
| Baja| D| `r exitosBaja`| 




Antes de realizar las operaciones se debe verificar que np > 5 y nq > 5 para las dos poblaciones

Para ello tenemos los siguientes datos para la primera poblaci√≥n: 

p1 = x1/n1 = 4437/35342 = 0.1255446777

n1p1 = 35342 * 0.1255446777 = 4437

q1 = 1-p1 = 1 - 0.1255446777 = 0.8744553223

n1q1 = 35342 * 0.8744553223 = 30905
  
  
Y tenemos los siguientes datos para la segunda poblaci√≥n: 

p2 = x2/n2 = 825/6516 = 0.126611418

n2p2 = 6516 * 0.126611418 = 825

q2 = 1-p2 = 1 - 0.126611418 = 0.873388582

n2q2 = 6516 * 0.873388582 = 5691
  

                                        
Como ambos valores son mayores a 5 se procede a utilizar la funci√≥n prop.test con sus respectivos valores
```{r}
prop.test(x = c(length(exitos.alta$color) , length(exitos.baja$color)), n = c(length(gamaAlta$corte), length(gamaBaja$corte)))
```


**Resumen de la prueba**

| Dato| Valor|
|:--|:--|
| Valor observado| $z_{obs}$ = -0.0010667|
| Grados de libertad| No corresponde|
| Estad√≠stico de prueba| $\tilde{p_1}$ - $\tilde{p_2}$ = 0|
| Regi√≥n de aceptaci√≥n| ]-0.009939703, 0.007806222[|
| Regi√≥n de rechazo| ]-1, -0.009939703[ $\cup$ ]0.007806222, +1[|
| Nivel de confianza| 0.95|


**Conclusi√≥n:**

\(H_{0}\) no puede ser rechazado dado que no se encontr√≥ evidencia suficiente para rechazarlo, ya que seg√∫n lo observado el 0 se encuentra dentro del intervalo de aceptaci√≥n y el valor p es mayor que el valor de alfa por lo que lo ubica en la regi√≥n de aceptaci√≥n, y por ende se asume que la proporci√≥n de diamantes de gama alta con color de tipo D se puede considerar similar a la proporci√≥n de diamantes de gama baja con color de tipo D.   

## Prueba de hip√≥tesis para una diferencia de promedios usando distribuci√≥n z

Para este ejemplo se utilizar√°n dos grupos (los mismo utilizados para la prueba del IC). En primer lugar, est√° el grupo de diamantes que se considera que tienen un color de buena calidad, este grupo est√° compuesto de aquellos diamantes cuyo color es "D", "E" o "F". Luego se tiene el grupo diamantes cuyo color es de peor calidad, el cual est√° compuesto por los diamantes con colores "H", "I" o "J". Ambos grupos est√°n distribuidos de la siguiente manera:

```{r}
buenaCalidad <- diamantes[diamantes$color == "D" | diamantes$color == "E" | diamantes$color == "F",]
peorCalidad <- diamantes[diamantes$color == "H" | diamantes$color == "I" | diamantes$color == "J",]

length(buenaCalidad$color)
length(peorCalidad$color)
```

| Calidad| Colores| Tama√±o de muestra|
|:--|:--|:--|
| Buena| D, E o F| `r length(buenaCalidad$color)`|
| Peor| H, I o J| `r length(peorCalidad$color)`|

**Hip√≥tesis asumidas**

Dado que ambas muestras son mayores a 30 se puede asumir que ambas siguen una distribuci√≥n normal y que se puede aproximar œÉ‚ÇÅ y œÉ‚ÇÇ mediante s‚ÇÅ  y s‚ÇÇ. Adem√°s, ambos grupos son independientes.

**C√°lculo**

Sea:

* $\mu_{b}$: la media de la profundidad de los diamantes de buena calidad
* $\mu_{m}$: la media de la profundidad de los diamantes de peor calidad

Y dadas las siguientes hip√≥tesis para la prueba:

* $H_{0}: \mu_{b} - \mu_{m} = 0$
* $H_{1}: \mu_{b} - \mu_{m} > 0$

Una vez obtenidos estos datos se procede a realizar la prueba de hip√≥tesis haciendo uso de las siguientes funciones:

```{r}
BSDA::z.test(x = buenaCalidad$profundidad, y = peorCalidad$profundidad, sigma.x = sd(buenaCalidad$profundidad), sigma.y = sd(peorCalidad$profundidad), mu = 0, alternative = "greater")
PASWR2::z.test(x = buenaCalidad$profundidad, y = peorCalidad$profundidad, sigma.x = sd(buenaCalidad$profundidad), sigma.y = sd(peorCalidad$profundidad), mu = 0, alternative = "greater")
```

Ambas funciones aplican para una y dos poblaciones y est√°n compuestas de los siguientes par√°metros, en donde:

* **x:** vector num√©rico que representa la primera muestra
* **y:** vector num√©rico que representa la segunda muestra (opcional)
* **sigma.x:** desviaci√≥n est√°ndar de x (opcional)
* **sigma.y:** desviaci√≥n est√°ndar de y (opcional)
* **mu:** el valor de la media o la diferencia de medias en la hip√≥tesis nula
* **alternative:** indica si la prueba es de cola izquierda (less), derecha (greater) o de dos colas (two.sided)

**Resumen de la prueba**

| Dato| Valor|
|:--|:--|
| Valor observado| $z_{obs} = -11.432$|
| Grados de libertad| No corresponde|
| Estad√≠stico de prueba| $\tilde{x}_b$ - $\tilde{x}_m$ = 0|
| Regi√≥n de aceptaci√≥n| ]-0.1889905, +$\infty$[|
| Regi√≥n de rechazo| ]-$\infty$, -0.1889905[|
| Nivel de confianza| 0.95|

**Conclusiones**

No se encontr√≥ evidencia en contra $H_{0}$ por lo cual se puede asumir que la media de la profundidad de diamantes con color de mejor calidad es menor a la de los diamantes con color de peor calidad. Esto concordando tambi√©n con los resultados del valor P, donde se tiene una aceptaci√≥n fuerte de $H_{0}$.

## Prueba de hip√≥tesis para un cociente de varianzas

Para este caso se utilizar√°n muestras aleatorias sin reemplazo de tama√±o 25 de los dos mismos grupos utilizados en c√°lculo del IC para diferencia de promedios con distribuci√≥n t (diamantes con color de buena calidad y diamantes con color de peor calidad).

```{r}
# Se sacan los datos de la calidad
buenaCalidad <- diamantes[diamantes$color == "D" | diamantes$color == "E" | diamantes$color == "F",]
peorCalidad <- diamantes[diamantes$color == "H" | diamantes$color == "I" | diamantes$color == "J",]

# Se toman las filas para las muestras aleatorias
set.seed(6894)
filas.randomMejorCalidad <- sample(1:length(buenaCalidad$color), 25, replace= F)
filas.randomPeorCalidad <- sample(1:length(peorCalidad$color), 25, replace= F)

muestraMejorCalidad <- as.data.frame(buenaCalidad[filas.randomMejorCalidad,])
muestraPeorCalidad <- as.data.frame(peorCalidad[filas.randomPeorCalidad,])

length(muestraMejorCalidad$color)
length(muestraPeorCalidad$color)
```

| Calidad| Colores| Tama√±o de muestra|
|:--|:--|:--|
| Buena| D, E o F| `r length(muestraMejorCalidad$color)`|
| Peor| H, I o J| `r length(muestraPeorCalidad$color)`|

Previamente ya se hab√≠a realizado una prueba de normalidad de estas muestras en el c√°lculo del IC para diferencia de promedio, sin embargo, aqu√≠ se adjunta la prueba de nuevo:

```{r echo=FALSE}
ggdensity(muestraMejorCalidad$profundidad, 
          main = "Gr√°fico de densidad de la profundidad de la muestra A",
          xlab = "Profundidad de los diamantes")
```

```{r echo=FALSE}
ggdensity(muestraPeorCalidad$profundidad, 
          main = "Gr√°fico de densidad de la profundidad de la muestra B",
          xlab = "Profundidad de los diamantes")
```

**Hip√≥tesis asumidas**

* El nivel de confianza utilizado ser√° de 95%.
* La poblaci√≥n 1 y la poblaci√≥n 2 se comportan normalmente.

**C√°lculo**

Sea:

* $\sigma^{2}_{b}$: la media de la profundidad de los diamantes de buena calidad
* $\sigma^{2}_{m}$: la media de la profundidad de los diamantes de peor calidad

Y dadas las siguientes hip√≥tesis para la prueba:

* $H_{0}: \frac{\sigma^{2}_{b}}{\sigma^{2}_{m}} = 1$
* $H_{1}: \frac{\sigma^{2}_{b}}{\sigma^{2}_{m}} ‚â† 0$

Una vez obtenidos estos datos se procede a realizar la prueba de hip√≥tesis haciendo uso de la siguiente funci√≥n:

```{r}
stests::var.test(x = muestraMejorCalidad$profundidad, y = muestraPeorCalidad$profundidad)
```

Donde:

* **x:** primera muestra
* **y:** segunda muestra (opcional)
* **alternative:** si es de cola derecha, doble cola o cola izquierda (opcional)
* **null.value:** por defecto es 1 considerando que la relaci√≥n entre las varianzas es 1. (opcional)
* **conf.level:** nivel de confidencia (opcional)

**Resumen de la prueba**

| Dato| Valor|
|:--|:--|
| Valor observado| $f_{obs} = 2.8255$|
| Grados de libertad| $v_{b} = 24$ $v_{m} = 24$|
| Estad√≠stico de prueba| $\frac{s^{2}_{b}}{s^{2}_{m}}=0$|
| Regi√≥n de aceptaci√≥n| ]1.245114, 6.411864[|
| Regi√≥n de rechazo| ]-$\infty$, 1.245114[$\cup$]6.411864, +$\infty$[|
| Nivel de confianza| 0.95|

**Conclusiones**

Se lleg√≥ a encontrar evidencia contra $H_{0}$ por lo cual se puede asumir que la varianza de la profundidad de diamantes con color de mejor calidad es distinta a la de los diamantes con color de peor calidad. Esto concordando tambi√©n con los resultados del valor P, donde se tiene un rechazo fuerte de $H_{0}$.


## Prueba de hip√≥tesis para una diferencia de promedios usando distribuci√≥n t

Para este caso se utilizar√°n muestras las mismas muestras del ejemplo anterior (diamantes con color de buena calidad y diamantes con color de peor calidad).

```{r}
# Se sacan los datos de la calidad
buenaCalidad <- diamantes[diamantes$color == "D" | diamantes$color == "E" | diamantes$color == "F",]
peorCalidad <- diamantes[diamantes$color == "H" | diamantes$color == "I" | diamantes$color == "J",]

# Se toman las filas para las muestras aleatorias
set.seed(6894)
filas.randomMejorCalidad <- sample(1:length(buenaCalidad$color), 25, replace= F)
filas.randomPeorCalidad <- sample(1:length(peorCalidad$color), 25, replace= F)

muestraMejorCalidad <- as.data.frame(buenaCalidad[filas.randomMejorCalidad,])
muestraPeorCalidad <- as.data.frame(peorCalidad[filas.randomPeorCalidad,])

length(muestraMejorCalidad$color)
length(muestraPeorCalidad$color)
```

| Calidad| Colores| Tama√±o de muestra|
|:--|:--|:--|
| Buena| D, E o F| `r length(muestraMejorCalidad$color)`|
| Peor| H, I o J| `r length(muestraPeorCalidad$color)`|

**Hip√≥tesis asumidas**

Por el ejemplo anterior se puede asumir que ambas muestras siguen una distribuci√≥n normal y que las varianzas son distintas.

**C√°lculo**

Sea:

* $\mu_{b}$: la media de la profundidad de los diamantes de buena calidad
* $\mu_{m}$: la media de la profundidad de los diamantes de peor calidad

Y dadas las siguientes hip√≥tesis para la prueba:

* $H_{0}: \mu_{b} - \mu_{m} = 0$
* $H_{1}: \mu_{b} - \mu_{m} > 0$

Una vez obtenidos estos datos se procede a realizar la prueba de hip√≥tesis haciendo uso de las siguientes funciones:

```{r}
t.test(x = muestraMejorCalidad$profundidad, y = muestraPeorCalidad$profundidad, mu = 0, alternative = "greater", var.equal = F)
```

La funci√≥n est√° compuesta de los siguientes par√°metros, en donde:

* **x:** vector num√©rico que representa la primera muestra
* **y:** vector num√©rico que representa la segunda muestra (opcional)
* **mu:** el valor de la media o la diferencia de medias en la hip√≥tesis nula
* **alternative:** indica si la prueba es de cola izquierda (less), derecha (greater) o de dos colas (two.sided)
* **var.equal** indica si las varianzas se asumen iguales

**Resumen de la prueba**

| Dato| Valor|
|:--|:--|
| Valor observado| $t_{obs} = -0.64071$|
| Grados de libertad| 39|
| Estad√≠stico de prueba| $\tilde{x}_b$ - $\tilde{x}_m$ = 0|
| Regi√≥n de aceptaci√≥n| ]-0.7404251, +$\infty$[|
| Regi√≥n de rechazo| ]-$\infty$, -0.7404251[|
| Nivel de confianza| 0.95|

**Conclusiones**

No se encontr√≥ evidencia en contra $H_{0}$ por lo cual se puede asumir que la media de la profundidad de diamantes con color de mejor calidad es menor a la de los diamantes con color de peor calidad. Esto concordando tambi√©n con los resultados del valor P, donde se tiene una aceptaci√≥n fuerte de $H_{0}$.

## Prueba de hip√≥tesis para una varianza

Para este caso de hip√≥tesis se estar√° usando como muestra la variable de quilates del dataset diamantes

```{r}
quilates <- diamantes$quilate
```
| Muestra| Tama√±o|
|:--|:--|
| Quilates| `r length(quilates)`|

**Hip√≥tesis asumidas**

Antes de realizar el c√°lculo es importante asumir que la muestra sigue una distribuci√≥n normal

**C√°lculo**

Sea:

* $\sigma^2$: la varianza de la variable quilates de la muestra

Y dadas las siguientes hip√≥tesis para la prueba:

* $H_{0}: \sigma =\sqrt{0.2246867} = 0.47401$
* $H_{1}: \sigma ‚â† 0.47401$

Una vez obtenidos estos datos se procede a realizar la prueba de hip√≥tesis haciendo uso de las siguientes funciones:

```{r}
sigma.test(x = quilates, sigma = 0.47401, alternative = "two.sided", conf.level = 0.95)
```

La funci√≥n est√° compuesta de los siguientes par√°metros, en donde:

* **x:** vector num√©rico que representa la primera muestra
* **sigma:** es la desviaci√≥n est√°ndar de la muestra
* **alternative:** indica si la prueba es de cola izquierda (less), derecha (greater) o de dos colas (two.sided)
* **conf.level:** Indica el nivel de confianza con el que se realiza la prueba

**Resumen de la prueba**

| Dato| Valor|
|:--|:--|
| Valor observado| $ùí≥^{2}_{obs} = 53939$|
| Grados de libertad| $v = 53939$|
| Estad√≠stico de prueba| $s^{2} = 0.2246867$|
| Regi√≥n de aceptaci√≥n| ]0.2220290, 0.2273925[|
| Regi√≥n de rechazo| ]-$\infty$, 0.2220290[ $\cup$ ]0.2273925, +$\infty$[|
| Nivel de confianza| 0.95|

**Conclusiones**

No se encontr√≥ evidencia en contra de $H_{0}$ por lo cual se puede asumir que la varianza de la muestra si es de 0.2246867, esto debido a que el valor de p es muy cercano a 1 y porque qu√© valor dado por la funci√≥n sobre la varianza muestral si se encuentra entre el intervalo ]0.2220290, 0.2273925[

# IV Parte: Otras pruebas de hip√≥tesis en R

## Caso 1:

Para este caso se utilizar√° la base de datos KidsFeet del paquete mosaicData:

```{r}
str(KidsFeet)
```

```{r}
feetsplit <- split(KidsFeet$length, KidsFeet$sex)

str(feetsplit)
```
Como pudimos observar, la funci√≥n split dividi√≥ la base de datos en dos, con B para los ni√±os y G para las ni√±as, se proceder√° a almacenarla en las siguientes variables:

```{r}
boys.feets <- feetsplit$B
girls.feets <- feetsplit$G
```

1. Gr√°ficos

Debido a que los tama√±os de las muestras de los ni√±os es de 20 y el de las ni√±as de 19, se pueden crear distinas gr√°ficas para determinar si dicha muestra sigue una distribuci√≥n normal.A continuaci√≥n se presentan los gr√°ficos de densidad 

```{r}
ggdensity(
  boys.feets, 
  main = "Gr√°fico de densidad de los ni√±os",
  xlab = "Tama√±o del largo de los pies en cent√≠metros"
)
```

```{r}
ggdensity(
  girls.feets, 
  main = "Gr√°fico de densidad de las ni√±as",
  xlab = "Tama√±o del largo de los pies en cent√≠metros"
)
```

```{r}
mean(boys.feets)
mean(girls.feets)
```

**¬øSe puede intuir una posible normalidad para los datos?**

Como se puede observar, probablemente exista normalidad en ambas muestras de datos, ya que parece ser que la gr√°fica tiene forma de campana, adem√°s, en ambos casos la punta de la gr√°fica se encuentra muy cerca de la media.


2. Gr√°fico QQ-plot

A continuaci√≥n se presentan los gr√°ficos de QQ-plot;

```{r}
qqnorm(boys.feets, ylab = "Largo del pie", main = "Gr√°fico QQ Plot de los ni√±os")
qqline(boys.feets)
```
```{r}
qqnorm(girls.feets, ylab = "Largo del pie", main = "Gr√°fico QQ Plot de las ni√±as")
qqline(girls.feets)
```

En ambos casos, parece ser que el conjunto de datos no parece seguir una distribuci√≥n normal, especialmente cerca de las colas.

3. Pruebas formales de normalidad S-W test, A-D test, K-S-L test

**Test de Shapito-Wilks o S-W test**

```{r}
boys.sw <- shapiro.test(boys.feets)
boys.sw

girls.sw <- shapiro.test(girls.feets)
girls.sw
```
Para ambos casos, no se encontr√≥ evidencia en contra para asumir normalidad, debido a que el valor p es mayor que el nivel de significancia (0.05).

**Test de normalidad de Anderson-Darling o A-D test**

```{r}
boys.ad <- ad.test(boys.feets)
boys.ad

girls.ad <- ad.test(girls.feets)
girls.ad
```
En ambos casos, no se encontr√≥ evidencia en contra para asumir normalidad, debido a que el valor p es mayor que el nivel de significancia (0.05).

**Test de Kolmogorov-Smirnov-Lilliefors o K-S-L test**

```{r}
boys.ksl <- lillie.test(boys.feets)
boys.ksl

girls.ksl <- lillie.test(girls.feets)
girls.ksl
```
En ambos casos, no se encontr√≥ evidencia en contra para asumir normalidad, debido a que el valor p es mayor que el nivel de significancia (0.05).

4. D'Agostino-Pearson

Para realizar esta prueba, es necesario saber que el tama√±o de la muestra obligatoriamente debe de ser de tama√±o 20 o superior, por ende, no es posible realizar la prueba para el caso del tama√±o de las ni√±as debido a que dicha muestra es de tama√±o 19. Sabiendo esto, se procede a realizar la prueba para el tama√±o de la muestra en general y luego para la muestra de los ni√±os:

```{r}
dagoTest(KidsFeet$length)
boys.dap <- dagoTest(boys.feets)
boys.dap
```
No se encontr√≥ evidencia en contra para asumir normalidad, debido a que el valor p general (Omnibus) es mayor que el nivel de significancia (0.05).

5. An√°lisis de custoris y simetr√≠a de los datos

A continuaci√≥n se mostrar√°n los an√°lisis de custoris en ni√±os y ni√±as para el tama√±o de la planta del pie:

```{r}
boys.kurtosis <- moments::kurtosis(boys.feets) # curtosis en ni√±os
boys.kurtosis

girls.kurtosis <- moments::kurtosis(girls.feets) # curtosis en ni√±as
girls.kurtosis
```

Como podemos observar, ambos resultados fueron mayores que cero, por lo que se puede concluir que ambos tienden a ser leptoc√∫rtica, es decir, su campana es alargada y muy punteada, con unas colas muy bajas.

A continuaci√≥n se mostrar√°n los an√°lisis de simetr√≠a en ni√±os y ni√±as para el tama√±o de la planta del pie:

```{r}
boys.skewness <- moments::skewness(boys.feets) # simetria en ni√±os
boys.skewness

girls.skewness <- moments::skewness(girls.feets) # simetria en ni√±as
girls.skewness
```

De la simetr√≠a se puede concluir que ambas gr√°ficas son sim√©tricas, aunque en el caso de los ni√±os, al ser positivo, su media est√° un poco m√°s inclinada hacia la izquierda, y en las ni√±as ocurre lo contrario, al ser negativo pero acerc√°ndose a 0, su media est√° ligeramente m√°s inclinada hacia la derecha.


## Caso 2:

Para este caso se utilizar√° la base de datos medidas_cuerpo de la siguiente url:

```{r}
url <- 'https://raw.githubusercontent.com/fhernanb/datos/master/medidas_cuerpo' 
body <- read.table(file=url, header=T)

str(body)
```

```{r}
biceps <- body$biceps
str(biceps)
```

1. Gr√°ficos

A continuaci√≥n se presentan los gr√°ficos de densidad para el tama√±o de los biceps:

```{r}
ggdensity(
  biceps, 
  main = "Gr√°fico de densidad de los biceps",
  xlab = "Tama√±o del largo de los biceps en cent√≠metros"
)
```

Se puede observar que la gr√°fica no tiene forma de campana y cerca de la media no existe un punto m√°ximo, por lo que se concluye que dicha muestra no sigue una distribuci√≥n normal.

2. Gr√°fico QQ-plot

A continuaci√≥n se presentan los gr√°ficos de QQ-plot, es importante saber que se utilizar√°n las edades para que as√≠ el gr√°fico del tama√±o de los biceps tenga sentido:

```{r}
#qqplot(biceps, body$edad, xlab = "Tama√±o de los biceps", ylab = "Edad de la persona", main = "Gr√°fico QQ Plot de los biceps")
qqnorm(biceps, ylab = "Tama√±o de los biceps", main = "Gr√°fico QQ Plot del tama√±o de los biceps")
qqline(biceps)
```

Se puede observar que el conjunto de datos no parece seguir una distribuci√≥n normal, especialmente en las colas y en el centro de la gr√°fica.

3. Pruebas formales de normalidad S-W test, A-D test, K-S-L test

**Test de Shapito-Wilks o S-W test**

```{r}
biceps.sw <- shapiro.test(biceps)
biceps.sw
```

Se encontr√≥ evidencia en contra para asumir normalidad, debido a que el valor p es menor que el nivel de significancia de 0.05.

**Test de normalidad de Anderson-Darling o A-D test**

```{r}
biceps.ad <- ad.test(biceps)
biceps.ad
```
Se encontr√≥ evidencia en contra para asumir normalidad, debido a que el valor p es menor que el nivel de significancia de 0.05.

**Test de Kolmogorov-Smirnov-Lilliefors o K-S-L test**

```{r}
biceps.ksl <- lillie.test(biceps)
biceps.ksl
```
Se encontr√≥ evidencia en contra para asumir normalidad, debido a que el valor p es menor que el nivel de significancia de 0.05.

4. D'Agostino-Pearson

```{r}
biceps.dap <- dagoTest(biceps)
biceps.dap
```
Se encontr√≥ evidencia en contra para asumir normalidad, debido a que el valor p general (Omnibus) es menor que el nivel de significancia de 0.05.

5. An√°lisis de custoris y simetr√≠a de los datos

A continuaci√≥n se mostrar√°n el an√°lisis de custoris para el tama√±o de los biceps:

```{r}
biceps.kurtosis <- moments::kurtosis(biceps) # curtosis de los biceps
biceps.kurtosis
```

Como se puede observar, el resultado fue mayor a cero, por lo que se puede concluir que tiende a ser leptoc√∫rtica, es decir, su campana es alargada y muy punteada, con unas colas muy bajas.

A continuaci√≥n se mostrar√° el an√°lisis de simetr√≠a para el tama√±o de los biceps:

```{r}
biceps.skewness <- moments::skewness(biceps) # simetria en medida de biceps
biceps.skewness
```

De la simetr√≠a se puede concluir la gr√°ficas es sim√©trica, aunque, al ser positivo, su media est√° un poco m√°s inclinada hacia la izquierda.

## Resumen casos 1 y 2

| Tipo de prueba| Ni√±os| Ni√±as| Medidas de biceps|
|:--|:--|:--|:--|
| Funci√≥n de densidad versus curva normal| Parece tener forma de campana| Parece tener forma de campana| No tiene forma de campana|
| Conclusi√≥n| Se concluye que sigue una dist. normal| Se concluye que sigue una dist. normal| Se concluye que no sigue una dist. normal|
| QQ-Plot| En las colas y el centro de la gr√°fica los datos est√°n m√°s alejados de la linea.| En las colas y el centro de la gr√°fica los datos est√°n m√°s alejados de la linea.| En las colas y el centro de la gr√°fica los datos est√°n m√°s alejados de la linea.|
| Conclusi√≥n| No parece seguir una distribuci√≥n normal| No parece seguir una distribuci√≥n normal| No parece seguir una distribuci√≥n normal|
| S-W test| Valor P=`r round(boys.sw$p.value, 4)`| Valor P=`r round(girls.sw$p.value, 4)`| Valor P=`r round(biceps.sw$p.value, 4)`|
| Conclusi√≥n| Se asume normalidad; valor p > 0.05 (significancia)| Se asume normalidad; valor p > 0.05 (significancia)| NO se asume normalidad; valor p < 0.05 (significancia)|
| A-D test| Valor P=`r round(boys.ad$p.value, 4)`| Valor P=`r round(girls.ad$p.value, 4)`| Valor P=`r round(biceps.ad$p.value, 4)`|
| Conclusi√≥n| Se asume normalidad; valor p > 0.05 (significancia)| Se asume normalidad; valor p > 0.05 (significancia)| NO se asume normalidad; valor p < 0.05 (significancia)|
| D'Agostino-Pearson| Valor P=0.7267| Valor P=NA| Valor P=0.00108|
| Conclusi√≥n| Se asume normalidad; valor p > 0.05 (significancia)| No aplica, n=19 y se requiere m√≠nimo 20| NO se asume normalidad; valor p < 0.05 (significancia)|
| Curtosis y simetr√≠a| `r round(boys.kurtosis, 4)` y `r round(boys.skewness, 4)`| `r round(girls.kurtosis, 4)` y `r round(girls.skewness, 4)`| `r round(biceps.kurtosis, 4)` y `r round(biceps.skewness, 4)`|
| Conclusi√≥n| Leptoc√∫rtica y sim√©trica| Leptoc√∫rtica y sim√©trica| Leptoc√∫rtica y sim√©trica|
| Conclusi√≥n general sobre normalidad de los datos| Se asume normalidad ya que a pesar de que gr√°ficamente no lo parezca, el valor p es un dato m√°s acertado que el factor visual| Se asume normalidad ya que a pesar de que gr√°ficamente no lo parezca, el valor p es un dato m√°s acertado que el factor visual| NO se asume normalidad|

## Caso 3:

La siguiente tabla resume los datos de obtenidos de v√≠ctimas de cr√≠menes elegidas al azar (seg√∫n datos del Departamento de Justicia de USA):

| Descripci√≥n| HOMICIDIO| ROBO| ASALTO|
|:--|:--|:--|:--|
| **El criminal era un extra√±o**| 12| 379| 727|
| **El criminal era un conocido o pariente**| 39| 106| 642|

Con los datos anteriores, ¬øser√≠a posible considerarque el tipo de delito es independiente de la condici√≥n del delincuente?, o por el contrario, ¬øexiste alguna relaci√≥n entre el tipo de delito con respecto al quien comete el acto? Se asumen un nivel de significancia de 5%.

Para este caso se plantea una prueba de independencia con las siguientes hip√≥tesis:

\(H_{0}:\):| El tipo de delito es independiente de la condici√≥n del delincuente

\(H_{1}:\):| No existe independencia entre el tipo de delito y la condici√≥n del delicuente



Para las pruebas de independencia se utilizar√° la funci√≥n chisq.test

Su sintaxis es:

          chisq.test(matrix(c(valores matriz), tama√±o matriz))




Y se procede a utilizar la funci√≥n chisq.test con los respectivos valores de la matriz que se present√≥ al inicio y su tama√±o el cual es 2x3 (2 filas y 3 columnas)

```{r}

chisq.test(matrix(c(12,379,727,39,106,642),2,3,byrow = TRUE))

```


**Resumen de la prueba**


| Dato| Valor|
|:--|:--|
| Tipo de prueba:| Independencia|
| Valor observado| 119.33|
| Grados de libertad| 2,  representan el total de filas -1 multiplicado por el total de columnas -1|                 
| Valor P|   2.2e-16|               
| \(H_{0}:\):| El tipo de delito es independiente de la condici√≥n del delincuente|       
| \(H_{1}:\):| No existe independencia entre el tipo de delito y la condici√≥n del delicuente|


**Conclusi√≥n**

Se cuenta con sufuciente evidencia para rechazar \(H_{0}\) ya que el valor p es muy cercano a 0, por lo tanto no se puede aceptar independencia del tipo de delito con respecto a la condici√≥n del delincuente


## Caso 4:

Considerando la siguiente situaci√≥n

La seguridad de los autom√≥viles se determina mediante diversas pruebas. Una de ellas  consiste en hacer chocar un autom√≥vil contra una barrera fija a 35 ùëöùëñ/‚Ñé con un maniqu√≠ colocado en el asiento del conductor.
A una de las medidas utilizadas para cuantificar el impacto del choque sobre el conductor se le conoce como **Desaceleraci√≥n de pecho** y se mide en unidades de fuerza de gravedad (ùëî). Los valores m√°s grandes indican mayores cantidades de desaceleraci√≥n, las cu√°les pueden provocar lesiones graves en los conductores. La siguiente tabla muestra mediciones de desaceleraciones de pecho obtenidas a partir de pruebas de choques de diferentes tipos de veh√≠culos:

| Autos compactos| Autos medianos| Autos grandes|
|:--|:--|:--|
| 44| 41| 32|
| 43| 49| 37|
| 44| 43| 38|
| 54| 41| 45|
| 38| 47| 37|
| 43| 44| 33|
| 42| 37| 38|
| 45| 34| 45|
| 50|   | 43|
|   |   | 42|

Con los datos anteriores, ¬øes posible considerar que el tama√±o del autom√≥vil puede variar en cuanto a la seguridad de sus pasajeros o por el contrario, es igualmente riesgoso? Se asume un nivel de significancia del 5%.


Para este caso se plantean las siguientes hip√≥tesis:

Sea:

X: las unidades de fuerza de gravedad para cuantificar el impacto del choque (Variable cuantitiativa)

Y: tipos de autos utilizados en las pruebas de choque (Variable cualitativa)

Œº1,Œº2 y Œº3 respectivamente las unidades de fuerza de gravedad promedio en los choques de cada tipo de auto.

\(H_{0}:\):Œº1=Œº2=Œº3.

\(H_{1}:\): al menos dos de las medias no son iguales.


Creamos un archivo csv con los datos de la tabla anterior y lo cargamos en la variable "datos" 

```{r}
library(readr)

datos <- read.csv("caso4.csv", sep = ";") 
head(datos, 5)

```


Aplicamos la prueba de varianza con la funcion aov y datos del csv (el summary es para hacer un resumen de los resultados):

```{r}
summary(aov(gravedad ~ autos, data = datos))
```



**Resumen de la prueba**


| Dato| Valor|
|:--|:--|
| Tipo de prueba:| ANOVA|
| Valor observado| 3.552|
| Grados de libertad autos| 2,  cantidad de tipos de autos - 1|  
| Grados de libertad residuals| 24,  representan el total de filas(datos de fuerza de gravedad) -1 |  
| SSE| 535.6|
| SSA| 158.5|
| SST| 694.1|
| S1| 79.26|
| S2| 22.31|
| Valor P|   0.0445|               
| \(H_{0}:\):| Œº1=Œº2=Œº3|       
| \(H_{1}:\):| al menos dos de las medias no son iguales|


**Conclusi√≥n**

En esta prueba el p-valor est√° dado por el resultado Pr(>F), que en este caso al ser menor que Œ±, se rechaza la hip√≥tesis nula, la cual indica que Œº1,Œº2 y Œº3 son iguales, por lo que si es posible asegurar que el tama√±o del automovil puede variar en cuanto a la seguridad de sus pasajeros


**4.2**

Para decir en cu√°les tipos de autos existe una verdadera diferencia significativa realizaremos una prueba Tuckey

Para despejar esta duda, se recomienda utilizar la prueba Tuckey que permite calcular la diferencia de impacto de cada valor en cada variable independiente. La prueba Tuckey la realizamos de la siguiente manera:


```{r}
# Almacenamos la prueba de ANOVA en una nueva variable
AnovaCaso4 <- aov(gravedad ~ autos, data = datos)

#Pasamo la prueba ANOVa a la prueba Tuckey
TukeyHSD(AnovaCaso4)
```
Del resumen anterior, debe comprenderse lo siguiente:

diff: corresponde a la resta de los promedios muestrales entre las dos categor√≠as comparadas

lwr: extremo izquierdo del IC

upr: extremo derecho del IC

p adj: valorP ajustado (para efectos pr√°cticos, el valor P de la prueba)


**Conclusion**

La prueba muestra que hay una diferencia significativa entre autos  "grandes" y "compactos" donde valorP=0.0351275 < Œ±=0.05, no as√≠ en el resto de comparaciones. 


# V Parte: Modelos de regresi√≥n lineal

## Caso 5:

Primeramente se cargan los datos de **EdadPesoGrasas.txt** como se muestra a continuaci√≥n:

```{r}
grasas <- read.table('http://verso.mat.uam.es/~joser.berrendero/datos/Eda
dPesoGrasas.txt', header = TRUE)
```

Con estos datos se proceden a realizar los siguientes puntos de un an√°lisis de regresi√≥n lineal:

### 1. Analisis de correlaci√≥n entre todas la variables.

Para esto se hace uso de la funci√≥n cor del paquete stats de R, con la cual se puede resumir de manera muy sencilla todos los posibles casos de correlaci√≥n en una matriz:

```{r}
c <- cor(grasas)
c
```

Adicional a esta matriz, tambi√©n se puede hacer uso de la funci√≥n corrplot del paquete del mismo nombre. Esta funci√≥n permite representar los datos de la matriz anterior de una manera m√°s intuitiva.

```{r}
corrplot(c)
```

De este gr√°fico se puede observar que conforme los datos est√°n m√°s lejos 0 los c√≠culos son m√°s grandes, esto indica que existe una correlaci√≥n entre las variables. En caso de que el color sea azul significa que es una correlaci√≥n positiva y si es rojo es una correlaci√≥n negativa. Por ejemplo en el caso de las variables edad y grasas se tiene que hay correlaci√≥n positiva que indica que el aumento de una se debe en gran parte debido a la otra.

### 2. Genraci√≥n de modelo RLS de mejor ajuste para dos variables con mayor coeficiente de correlaci√≥n

Para este punto se har√° uso de la variables edad y grasas que fueron las que tuvieron un mayor coeficiente de variaci√≥n seg√∫n los datos del punto anterior.

De esto se tiene que grasas ser√° la variable Y de respuesta y que edad ser√° la la variable X explicativa. A partir de estos datos se procede a generar el RLS haciendo uso de la funci√≥n lm del paquete stats de R

```{r}
modelo <- lm(grasas ~ edad, data = grasas)
modelo
```

De esto se tiene que el modelo de RLS ser√≠a grasas = 102.575 + 5.321*edad

### 3. An√°lisis de la calidad del modelo generado

Para esto se har√° uso del coeficiente de correlaci√≥n y el coeficiente de determinaci√≥n. Se utilizar√° la funci√≥n summary para extraer el par√°metro r.squared del modelo c√°lculado previamente y posteriormente se har√° el an√°lisis de los coeficientes.

```{r}
## C√°lculo del coeficiente de determinaci√≥n
summary(modelo)$r.squared

## C√°lculo del coeficiente de correlaci√≥n
sqrt(summary(modelo)$r.squared)
```

Se tiene que $R = 0.8373534$, esto significa que la correlaci√≥n lineal entre grasas y edad es positiva y moderada. Por otra parte, se tiene que $R^{2} = 0.7011607$, de esto se interpreta que el 70.11% de variaci√≥n en las grasas se debe a la edad y el restante 29.89% es por otros factores.

De todo esto se puede llegar a la conclusi√≥n de que el modelo tiene una calidad de moderada ya que hay un buen porcentaje otros factores que explican la variaci√≥n de grasas y adem√°s el nivel de correlaci√≥n no supera el 90%.

### 4. Gr√°fico de dispersi√≥n y recta de mejor ajuste

En este punto se genera un gr√°fico de RLS mediante el uso de la funci√≥n geom_point del paquete ggplot2 de R:

```{r}
graficoGrasas <- ggplot(grasas, aes(edad, grasas))
graficoGrasas + geom_point(alpha = 0.4) + geom_smooth(method = "lm")
```

Para un IC del 95% se puede visualizar que la calidad del modelo se encuentra en un nivel moderado, ya que a pesar de que hay varios puntos dentro de la zona del IC hay una cantidad similar que se encuentran por fuera. Esto concordando tambi√©n con lo visualizado mediante los coeficiente de correlaci√≥n y determinaci√≥n.

### 5. Prueba de normalidad de residuos

Con el fin de verificar si el los datos pueden ajustarse de manera lineal, se procede a realizar una prueba para verificar si la distribuci√≥n de los errores o residuos se comporta de manera normal. Para ello se hace uso de la funci√≥n lillie.test del paquete nortest de R.

```{r}
b0 <- 102.575
b1 <- 5.321

grasas.estimada <- b0 + b1 * grasas$edad
errores <- grasas.estimada - grasas$grasas
lillie.test(errores)
```

Como el valor P es grande, no existe evidencia suficiente para rechazar la normalidad de los errores, por lo tanto se puede asumir la normalidad de los mismos, por lo que se cumple el principio.

### 6. Intervalo de confianza de 95% para los coeficientes del modelo

Con el objetivo de hallar los IC de los parametos $\beta_0$ y $\beta_1$, se hace uso de la funci√≥n confint del paquete stats:

```{r}
confint(modelo,level = 0.95)
```

Entonces se tiene que $\beta_0$ est√° entre ]41.265155, 163.885130[ y $\beta_1$ ]3.822367, 6.818986[

### 7. Para una edad de 27 a√±os, se determinar√° un IC de 95% para ùúáùëå|ùë•=27 y un intervalo de predicci√≥n para los valores de Y asociados a dicha edad.

Para el c√°lculo de estos dos par√°metros se hace uso de la funci√≥n predict.lm del paquete stats, la cual funciona tanto para intervalos de confidencia como de predicci√≥n.

Primero se calcula el intervalo de confidencia:

```{r}
x0 <- data.frame(edad = 27)
predict.lm(modelo, x0, interval = "confidence", level = 0.95)
```

Y se tiene que se encuentra entre ]220.6777, 271.7891[ con un nivel de confianza del 95%. Y significa que se espera que la media de grasa para una edad de 27 a√±os se encuentre en ese intervalo el 95% de las veces.

Luego se calcula el intervalo de predicci√≥n:

```{r}
x0 <- data.frame(edad = 27)
predict.lm(modelo, x0, interval = "prediction", level = 0.95)
```

Y se tiene que el intervalo de predicci√≥n con IC del 95% es ]152.7653, 339.7015[, lo que significa que se espera que el valor de grasa para una edad de 27 a√±os se encuentre en ese intervalo el 95% de las veces.

### 8. Verificaci√≥n de la linealidad entre las variables y de dependencia lineal entre estas.

Primero se tiene las siguientes hip√≥tesis:

* $H_0: \beta=0$ (no hay linealidad)
* $H_1: \beta‚â†0$

Para probar la siguiente hip√≥tesis se har√° uso de de la funci√≥n summary, esto con el obtener un resumen de los datos del modelo.

```{r}
summary(modelo)
```

Como en la pendiente el valor P es menor a 0.05 se rechaza $H_0$ por lo que se puede asumir que la pendiente es distinta de 0 lo que significa que hay linealidad y que hay dependencia lineal entre las variables grasas y edad.

## Caso 6:

```{r}
ventasdb <- read.csv("DatosVentas.csv", , header = TRUE)
ventasdb
```

**Generaci√≥n de los modelos**

##Regresion Lineal Simple
#1
```{r}
mod0 <- lm(ventas ~ tv, data = ventasdb)
mod0
```
Tras generar el modelo optenemos la ecuaci√≥n:

ventas = 7.03259 + 0.04754 * tv

##Regresion Lineal Multiple
#2
```{r}
mod1 <- lm(ventasdb$ventas ~ ventasdb$tv+ventasdb$radio+ventasdb$periodico)
mod1
```
Tras generar el modelo optenemos la ecuaci√≥n:

ventas = 2.938889 + 0.045765 * tv + 0.188530 * radio + -0.001037 * periodico

Tras optener los coeficientes podemos concluir que los que aportan a modelo son los de la variable tv y radio ya que estos son positivos, en cambio el de periodico al ser negativo mas bien esta restando al modelo.

#3
```{r}
mod2 <- lm(ventasdb$ventas ~ ventasdb$tv+ventasdb$radio)
mod2
```
Tras generar el modelo optenemos la ecuaci√≥n:

ventas = 2.92110 + 0.04575 * tv + 0.18799 * radio

En este caso los coeficientes muestran que ambos son significativos, sin embargo el de tv es muy poco ya que es muy cercano al valor 0.

#4
```{r}

mod3 <- lm(ventasdb$ventas ~ ventasdb$tv + ventasdb$radio + (ventasdb$tv*ventasdb$radio))
mod3
```
Tras generar el modelo optenemos la ecuaci√≥n:

ventas = 6.750220 + 0.019101 * tv + 0.028860 * radio + 0.001086(tv*radio)

Tras optener los resultados podemos ver que todos los coeficientes obtenidos son significativos ya que todos son positivos, siendo el menos significativo de todos el de tv * radio ya que es el mas cercano a 0

**Seleccionando el mejor modelo**

```{r}
## C√°lculo del coeficiente de determinaci√≥n mod0
cd0 <- summary(lm(mod0))$r.squared

## C√°lculo del coeficiente de correlaci√≥n mod0
cc0 <- sqrt(summary(mod0)$r.squared)

## C√°lculo del coeficiente de determinaci√≥n mod1
cd1 <- summary(lm(mod1))$r.squared

## C√°lculo del coeficiente de correlaci√≥n mod1
cc1 <- sqrt(summary(mod1)$r.squared)

## C√°lculo del coeficiente de determinaci√≥n mod2
cd2 <- summary(lm(mod2))$r.squared
cd2

## C√°lculo del coeficiente de correlaci√≥n mod2
cc2 <- sqrt(summary(mod2)$r.squared)
cc2

## C√°lculo del coeficiente de determinaci√≥n mod3
cd3 <- summary(lm(mod3))$r.squared

## C√°lculo del coeficiente de correlaci√≥n mod3
cc3 <- sqrt(summary(mod3)$r.squared)
```

#1
| Ecuaci√≥n del modelo| Coeficiente de correlaci√≥n| Coeficiente de determinaci√≥n|
|:--|:--|:--|
| ventas = 7.03259 + 0.04754 * tv|`r cc0` | `r cd0`|
| ventas = 2.938889 + 0.045765 * tv + 0.188530 * radio + -0.001037 * periodico| `r cc1`| `r cd1`|
| ventas = 2.92110 + 0.04575 * tv + 0.18799 * radio| `r cc2`| `r cd2`|
| ventas = 6.750220 + 0.019101 * tv + 0.028860 * radio + 0.001086(tv*radio)| `r cc3`| `r cd3`|

#2
Se tiene que para el modelo mod2 $R =$ `r cc2`, esto significa que la correlaci√≥n lineal entre las ventas y tv, radio es positiva y moderada. Por otra parte, se tiene que $R^{2} =$ `r cd2`, de esto se interpreta que el 94.72% de variaci√≥n en las venta se debe a la tv, radio y el restante 7.28% es por otros factores.

#3
```{r}
AICctab(mod0, mod1, mod2, mod3, base = T, delta = T, sort = T, weights = T, nobs = ncol(ventasdb))

```
Como podemos ver tras ejecutar la funcion el mejor modelo corresponde al mod3 con un puntaje de 490.3, luego mod1 con 722.4 en tercer lugar mod0 con 1068.1 y por ultimo mod2 que tiene un Inf.

#4
Como primer paso creamos los Explain Model
```{r}
exp_lm0 <- explain(mod0, data = ventasdb, label = "lm1", y = ventasdb$ventas)
exp_lm2 <- explain(mod2, data = ventasdb, label = "lm2", y = ventasdb$ventas)
exp_lm3 <- explain(mod3, data = ventasdb, label = "lm3", y = ventasdb$ventas)
```

Como segundo paso creamos los Performance Model
```{r}
lm0 <- model_performance(exp_lm0)
lm2 <- model_performance(exp_lm2)
lm3 <- model_performance(exp_lm3)
```

Por ultimo graficamos los modelos
```{r}
plot(lm0,lm2, lm3)
```
Como podemos ver en el gr√°fico el mejor modelo el el mod3 ya que presenta la curva mas baja de la grafica, como segundo mejor modelo el mod2 y como peor modelo el mod1, este criterio tiene sentido ya que ......... terminar

#5
An√°lisis de varianza
```{r}
anova(mod0,mod1, mod2, mod3)
```


# VI Parte: Modelos de regresi√≥n no lineal

## Caso 7:

Para esta secci√≥n se van a generar y analizar dos modelos de RNLS usando los datos de bones de la base de datos jaws, la cual contiene informaci√≥n sobre la longitud de la mand√≠bula de los venados, seg√∫n la edad.

### 1. Cargar los datos del archivo de texto.

```{r}
jaws <- read.table("jaws.txt", header=T)
```

### 2. Gr√°fico de dispersi√≥n de los datos.

```{r}
ggplot(jaws, aes(x = age, y = bone)) + geom_point()
```

### 3. Generar modelo RNLS

Para esta parte se generar√° un modelo RNLS de la forma $y=a(1- e^{-c x })$, para ello se har√° uso de la funci√≥n nlm() del paquete stats y se usar√°n como valores iniciales a = 120 y c = 0.064.

```{r}
modelo1 <- nls(bone~a*(1-exp(-c*age)), data = jaws, start = list(a=120, c=0.064))
modelo1
```

### Gr√°fico del modelo.

Ahora se proceder√° a realizar un gr√°fico del modelo anterior junto al de dispersi√≥n:

```{r}
xo <- seq(from = min(jaws$age) - 0.2, to = max(jaws$age) + 0.2, by = 0.01)
yo <- 120 * (1 - exp(-0.064 - xo))

# Graficamos dispersi√≥n y el modelo de ajuste en un mismo plot
plot(jaws$age, jaws$bone, main = "Modelo de RNLS f(x)=a(1- e^{-c x })", col = "darkblue", lwd = 2)
lines(xo, yo, type = "l")
```

### 5. Segundo modelo (selecci√≥n del modelo).

Para este punto se har√° un segundo modelo. Considerando que la gr√°fica tiene una asintota alrededor de 120 en el eje X y que parece tener tambi√©n una menor que 0 en el eje Y (ya que ya hay un punto que toca 0) se decidir√° por utilizar el modelo el modelo hiperb√≥lico ya que este contiene asintotas en ambos ejes y permite m√°s libertad en el posicionamiento de estas.

### 6. Linealizaci√≥n del segundo modelo.

En est√° parte se hara una estimaci√≥n de los par√°metros $\alpha$ y $\beta$ a trav√©s de un proceso de lineaci√≥n a partir de un modelo RLS, para esto se hara uso una vez m√°s de la funci√≥n lm haciendo la sistituci√≥n de variables respectiva, que es la siguiente:

$X_2 = \frac{1}{X}$ y $Y_2 = \frac{1}{Y}$

Teniendo en cuenta esto √∫ltimo se procede a realizar el RLS:

```{r}
X2 <- 1/jaws$age
Y2 <- 1/jaws$bone
datoslm <- cbind(X2, Y2)
datoslm.df <- as.data.frame(datoslm)

## Se eliminan los infinitos del caso 0/0
datoslm.df <- datoslm.df[!is.infinite(rowSums(datoslm.df)),]
modelolm <- lm(Y2 ~ X2, data = datoslm.df)
modelolm
```

Se tiene que:

$\alpha = 0.00523$ y $\beta = 0.10339$

### 7. Creaci√≥n del segundo RNLS.

A partir de la estimaci√≥n anterior de $\alpha$ y $\beta$ se proceder√° a utilizar la funci√≥n nls para generar un segundo modelo RNLS utilizando $\alpha$ y $\beta$ como los valores iniciales

```{r}
modelo2 <- nls(bone~(age)/(a*age+b), data = jaws, start = list(a=0.00523, b=0.10339))
modelo2
```

Finalmente se tiene que la ecuaci√≥n de RNLS es:

$y = \frac{x}{0.007261x+0.053404}$

### 8. Gr√°fico del segundo modelo RNLS.

En este punto se procede a realizar un gr√°fico del modelo generado en el paso anterior de la siguiente manera:

```{r}
xo <- seq(from = min(jaws$age) - 0.2, to = max(jaws$age) + 0.2, by = 0.01)
yo <- xo / (0.007261 * xo + 0.053404)

# Graficamos dispersi√≥n y el modelo de ajuste en un mismo plot
plot(jaws$age, jaws$bone, main = "Modelo de RNLS f(x)=a(1- e^{-c x })", col = "darkblue", lwd = 2)
lines(xo, yo, type = "l")
```

### 9. Comparaci√≥n de ambos modelos.

En este punto se compar√°n ambos modelos con el fin de cuantificar cual es mejor, para esto se hara uso de la funci√≥n anova del paquete stats de R.

```{r}
anova(modelo1, modelo2)
```

En este caso bajo el criterio de an√°lisis de varianzas el modelo 1 resulto ser el mejor ya que tiene un RSS menor. Sin embargo, esto parece no coincidir con la gr√°ficas ya que parece ser que la gr√°fica del modelo 2 se ajusta mejor a los datos en comparaci√≥n a la del modelo 1.
