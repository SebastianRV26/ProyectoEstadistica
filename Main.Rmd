---
title: "Proyecto de estadística: Etapa 3"
author: 
  - Sebastián Rojas Vargas
  - Francisco Soto Quesada
  - Jairo Pacheco Campos
  - Jason Barrantes Rodríguez
date: "10/06/2021"
output: word_document
---

# Lista de librerías utilizadas

```{r setup, message=F, warning=F, echo = T, results = 'hide'}
library(visdat)
library(ggplot2)
library(DataExplorer)
library(datos)
library(EnvStats)
library(stests)
library("ggpubr")
library(stats)
library(BSDA)
library(PASWR2)
library(TeachingDemos)
library(mosaicData) # para usar KidsFeet
library(nortest) # para usar A-D, S-W, K-S-L test
library(fBasics) # para usar D’Agostino-Pearson
library(moments) # para custoris y simetría
library(corrplot)
library(bbmle)
library(DALEX)
```

# I Parte: explicación de los datos

A continuación, se presenta una tabla con los principales aspectos del dataset utilizado.

**Dataset:** Diamantes

**Descripción general:** se optó por la utilización del dataset de diamantes del paquete de datos de R. El motivo de la elección de este es que cuenta con una gran cantidad de datos y columnas. Estas últimas siendo de gran variedad entre datos cualitativos y cuantitativos. Además de todo esto el dataset cuenta con todas sus variables y sus datos ya traducidos al español, facilitando así la comprensión de los datos.

**Filas:** 53 940

**Columnas:** 10

**Resumen del dataset:**

```{r}
str(diamantes)
```

**Resumen de los datos:**

```{r}
vis_dat(diamantes)
plot_missing(diamantes)
```

En esta última imagen se puede observar que no hay datos faltantes en las columnas del dataset. Esto facilita los cálculos que se vean a realizar más adelante ya que no hay necesidad de filtrar los datos faltantes.

## Resumen de variables seleccionadas

| Variables| Tipos| Descripción| Parámetro por estimar (IC)|
|:--|:--|:--|:--|
| Precio| Cuantitativa| Precio en dólares estadounidenses| Promedio usando distribución z y distribución t|
| Corte| Cualitativa| Calidad del corte (Regular, Bueno, Muy bueno, Premium, Ideal)| Proporción, diferencia de proporciones|
| Profundidad| Cuantitativa| Porcentaje de la profundidad total en milímetros| Diferencia de promedios usando distribución z y distribución t|
| Quilates| Cuantitativa| Peso del diamante| Cociente de varianzas y varianza.

# II Parte: Análisis Inferencial (IC)

## IC de un promedio usando distribución Z

A continuación, se presentan los promedios usando distribución normal estándar de una población de datos extraídos del dataset diamantes, utilizando los siguientes datos de la variable precio del dataset de diamantes:

```{r}
set.seed(4562) # semilla

poblacion <- as.data.frame(diamantes)
poblacion.precios <- poblacion$precio

n1 <- length(poblacion.precios)
mu1 <- mean(poblacion.precios)
var1 <- var(poblacion.precios)

```

| Muestra| Tamaño| Promedio| Varianza|
|:--|:--|:--|:--|
| A| `r n1`| `r mu1`| `r var1`|

**Hipótesis asumidas** 

Dado que la muestra es mayor a 30 se puede asumir que la distribución muestral de medias sigue una distribución normal y que se puede aproximar σ₁ mediante s₁.

**Cálculo**

Conociendo los datos se puede aproximar el IC utilizando la función z.test de las librerías stests BSDA y PASWR2.


Para stests los parámetros son los siguientes:

* **x:** vector numérico que representa la muestra
* **sigma2:** varianza de la muestra
* **conf.level:** nivel de confidencia (opcional, se asume 0.95 por defecto)

```{r}
stests::z.test(
  x = poblacion.precios, 
  sigma2 = var(poblacion.precios), 
  conf.level = 0.95
  )$conf.int
```


Los parámetros tanto para BSDA y PASWR2 son los siguientes:

* **x:** la muestra
* **sigma.x:** desviación estándar de la muestra
* **conf.level:** nivel de confidencia (opcional, se asume 0.95 por defecto)

```{r}
BSDA::z.test(
  x = poblacion.precios, 
  sigma.x = sqrt(var(poblacion.precios)), 
  conf.level = 0.95
  )$conf.int
```
```{r}
IC <- PASWR2::z.test(
  x = poblacion.precios, 
  sigma.x = sqrt(var(poblacion.precios)), 
  conf.level = 0.95
  )$conf.int

IC
```

**Conclusiones**

De los resultados obtenidos se puede concluir que la media de precios del dataset diamante se encuentra en el intervalo ]`r IC`[ con un 95% de confianza, resultado que coincide en las tres librerías utilizadas.

## IC de un promedio usando distribución t
A continuación, se presentan los promedios usando distribución t de una población, utilizando muestras de la variable precio del dataset de diamantes.

```{r}
## Se toman filas random para sacar del dataset
set.seed(6894)
filas.random <- sample(1:53940, 20, replace= T)

## Se generan datasets nuevos con las filas random anteriores 
muestra1 <- as.data.frame(diamantes[filas.random,])
muestra.precios <- muestra1$precio
n1 <- length(muestra.precios)
mu1 <- mean(muestra.precios)
de1 <- sqrt(var(muestra.precios))
alpha1 <- 0.05

```

| Muestra| Tamaño| Promedio| Desviación estándar|
|:--|:--|:--|:--|
| A| `r n1`| `r mu1`| `r de1`|

En este caso dado que el tamaño de la muestra es menor a 30 se ha optado por realizar una inspección visual de los datos para ver si se asemeja a una distribución normal.

```{r echo=FALSE}
ggdensity(muestra1$profundidad, 
          main = "Gráfico de densidad de la profundidad de la muestra A",
          xlab = "Precio de los diamantes")
```

**Hipótesis asumidas**

Como se puede observar, la muestra tiene forma de campana, por lo que se puede asumir que sigue una distribución normal. 

**Cálculo**

Conociendo esto se puede aproximar el IC mediante la función t.test, la cual tiene la siguiente estructura, con los siguientes parámetros:

* **x:** muestra
* **conf.level:** nivel de confidencia

```{r}
IC <- t.test(
  x = muestra.precios,
  conf.level = 0.95
  )$conf.int

IC
```

**Conclusión**

De los resultados obtenidos, se puede concluir que la media de precios del dataset de diamantes se encuentra en el intervalo ]`r IC`[ con un 95% de confianza. Además de esto, comparándolo con el IC de la distribución Z se puede observar que este posee menor precisión debido a la poca cantidad de datos que fueron brindados.

## IC de una proporción

A continuación, se presenta la proporción para una población de datos tomados del dataset diamantes, para ello se ha utilizado una muestra de la variable "corte" donde se incluyen todos los diamantes cuyo corte sea de tipo "Premium" o "Ideal", utilizando una muestra de gama alta de la siguiente manera:

```{r}
gamaAlta <- diamantes[diamantes$corte == "Premium" | diamantes$corte == "Ideal",]
length(gamaAlta$corte)
```

| Gama| Corte| Tamaño de muestra|
|:--|:--|:--|
| Alta| Premium e Ideal| `r length(gamaAlta$corte)`| 

Como sabemos el dataset diamantes contiene una variable llamada corte, de igual manera, este dataset contiene otra variable llamada color. Estas variables las utilizaremos para saber cuál es la proporción que existe de un diamante de corte premium o ideal que hemos llamado gama alta con respecto al color que este posee. Para ello utilizamos la población de diamantes de gama alta que sean de color tipo D:

```{r}
exitos.alta <- gamaAlta[gamaAlta$color == "D",]
length(exitos.alta$color)
```

| Color| Tamaño de muestra|
|:--|:--|
| D| `r length(exitos.alta$color)`| 

**Hipótesis asumidas**

Antes de realizar las operaciones se debe verificar que np > 5 y nq > 5

Para ello tenemos los siguientes datos:

$$p = \frac{x}{n} = \frac{4437}{35342} = 0.1255446777$$
$$np = 35342 * 0.1255446777 = 4437$$
$$q = 1-p = 1 - 0.1255446777 = 0.8744553223$$
$$nq = 35342 * 0.8744553223 = 30905$$
                                        
Como ambos valores son mayores a 5 es posible obtener la proporción. Una vez conocidos estos datos se puede calcular el IC de la proporción, para esto se implementa la función prop.test para una población de la siguiente manera:

**Cálculo**

Una vez conociendo todos los datos, se procede a calcular el intervalo de confianza para una proporción con un nivel de confianza del 95%:

```{r}
prop.test(x=length(exitos.alta$color), n=length(gamaAlta$corte), conf.level = 0.95)$conf.int
```

En donde:

* **x:** vector con el conteo de éxitos de la muestra
* **n:** vector con el número de ensayos la muestra
* **conf.level:** nivel de confianza

**Conclusiones**

De los resultados obtenidos se puede observar que el intervalo resultante es muy pequeño, esto debido a la gran cantidad de datos que se usaron para realizar el cálculo.

## IC de una diferencia de proporciones

A continuación, se presenta la diferencia de proporciones para dos poblaciones de datos tomados del dataset diamantes, para ello se han utilizado dos muestras de la variable "corte" donde en la primera se incluyen todos los diamantes cuyo corte sea de tipo "Premium" ó "Ideal" (muestra de gama alta) y la segunda muestra donde se incluyen todos los diamantes cuyo corte sea de tipo "Regular" ó  "Bueno" (muestra de gama baja), de la siguiente manera:

```{r}
gamaAlta <- diamantes[diamantes$corte == "Premium" | diamantes$corte == "Ideal",]
length(gamaAlta$corte)
gamaBaja <- diamantes[diamantes$corte == "Regular" | diamantes$corte == "Bueno",]
length(gamaBaja$corte)

exitos.alta <- gamaAlta[gamaAlta$color == "D",]
length(exitos.alta$color)
exitos.baja <- gamaBaja[gamaBaja$color == "D",]
length(exitos.baja$color)
```

| Gama| Corte| Tamaño de muestra|
|:--|:--|:--|
| Alta| Premium e Ideal| `r length(gamaAlta$corte)`|
| Baja| Regular y Bueno| `r length(gamaBaja$corte)`| 

Como sabemos el dataset diamantes contiene una variable llamada corte, de igual manera, este dataset contiene otra variable llamada color. Estas variables las utilizaremos para saber cuál es la diferencia de proporciones que existen de un diamante de gama alta y de gama baja con respecto al color que este posee. Para ello utilizamos la población de diamantes de gama alta y baja que sean de color tipo D para representar los éxitos:

| Gama | Color| Tamaño de muestra|
|:--|:--|:--|
| Alta| D| `r length(exitos.alta$color)`|
| Baja| D| `r length(exitos.baja$color)`| 

**Hipótesis asumidas**

Antes de realizar las operaciones se debe verificar que np > 5 y nq > 5 para las dos poblaciones

Para ello tenemos los siguientes datos para la primera población: 

$$p_{1} = \frac{x_{1}}{n_{1}} = \frac{4437}{35342} = 0.1255446777$$
$$n_{1}p_{1} = 35342 * 0.1255446777 = 4437$$
$$q_{1} = 1-p_{1} = 1 - 0.1255446777 = 0.8744553223$$
$$n_{1}q_{1} = 35342 * 0.8744553223 = 30905$$

Y tenemos los siguientes datos para la segunda población: 

$$p_{2} = \frac{x_{2}}{n_{2}} = \frac{825}{6516} = 0.126611418$$
$$n_{2}p_{2} = 6516 * 0.126611418 = 825$$
$$q_{2} = 1-p_{2} = 1 - 0.126611418 = 0.873388582$$
$$n_{2}q_{2} = 6516 * 0.873388582 = 5691$$
  
                                        
Como ambos valores son mayores a 5 significa que si se puede realizar la diferencia de proporciones. Una vez conocidos estos datos se puede calcular el IC para la diferencia de proporciones, para esto se implementa la función prop.test para dos poblaciones de la siguiente manera:


```{r}
prop.test(x = c(length(exitos.alta$color) , length(exitos.baja$color)), n = c(length(gamaBaja$corte), length(gamaAlta$corte)), conf.level = 0.95)$conf.int
```

En donde:

* **x:** vector con el conteo de éxitos de la muestra
* **n:** vector con el número de ensayos la muestra
* **conf.level:** nivel de confianza

De la cual se puede concluir que la proporción de la muestra A es mayor que el de la muestra B.

## IC de una diferencia de promedios usando distribución z

Para este ejemplo se utilizarán dos grupos. En primer lugar, está el grupo de diamantes que se considera que tienen un color de buena calidad, este grupo está compuesto de aquellos diamantes cuyo color es "D", "E" o "F". Luego se tiene el grupo diamantes cuyo color es de peor calidad, el cual está compuesto por los diamantes con colores "H", "I" o "J". Ambos grupos están distribuidos de la siguiente manera:

```{r}
buenaCalidad <- diamantes[diamantes$color == "D" | diamantes$color == "E" | diamantes$color == "F",]
peorCalidad <- diamantes[diamantes$color == "H" | diamantes$color == "I" | diamantes$color == "J",]

length(buenaCalidad$color)
length(peorCalidad$color)
```

| Calidad| Colores| Tamaño de muestra|
|:--|:--|:--|
| Buena| D, E o F| `r length(buenaCalidad$color)`|
| Peor| H, I o J| `r length(peorCalidad$color)`|

**Hipótesis asumidas**

Dado que ambas muestras son mayores a 30 se puede asumir que la distribución muestral de medias sigue una distribución normal y se puede aproximar σ₁ y σ₂ mediante s₁  y s₂.

**Cálculo**

Una vez obtenidos estos datos se desea calcular la diferencia de promedios de profundidad entre la población de buena calidad y la de peor calidad con un intervalo de confianza del 95%. Para esto se hace uso de las siguientes funciones:

```{r}
BSDA::z.test(x = buenaCalidad$profundidad, y = peorCalidad$profundidad, sigma.x = sd(buenaCalidad$profundidad), sigma.y = sd(peorCalidad$profundidad), conf.level = 0.95)$conf.int
PASWR2::z.test(x = buenaCalidad$profundidad, y = peorCalidad$profundidad, sigma.x = sd(buenaCalidad$profundidad), sigma.y = sd(peorCalidad$profundidad), conf.level = 0.95)$conf.int
```

Ambas funciones aplican para una y dos poblaciones y están compuestas de los siguientes parámetros, en donde:

* **x:** vector numérico que representa la primera muestra
* **y:** vector numérico que representa la segunda muestra (opcional)
* **sigma.x:** desviación estándar de x (opcional)
* **sigma.y:** desviación estándar de y (opcional)
* **conf.level:** nivel de confianza entre 0 y 1 (opcional, se asume 0.95 por defecto)

**Conclusiones**

De los resultados obtenidos para la diferencia de promedios se puede concluir que la media de profundidad de diamantes con colores de baja calidad es mayor que la diamantes con colores de alta calidad.

## IC de una diferencia de promedios usando distribución t

Para este caso se utilizarán muestras aleatorias sin reemplazo de tamaño 25 de los dos grupos utilizados en el cálculo anterior (diamantes con color de buena calidad y diamantes con color de peor calidad).

```{r}
# Se sacan los datos de la calidad
buenaCalidad <- diamantes[diamantes$color == "D" | diamantes$color == "E" | diamantes$color == "F",]
peorCalidad <- diamantes[diamantes$color == "H" | diamantes$color == "I" | diamantes$color == "J",]

# Se toman las filas para las muestras aleatorias
set.seed(6894)
filas.randomMejorCalidad <- sample(1:length(buenaCalidad$color), 25, replace= F)
filas.randomPeorCalidad <- sample(1:length(peorCalidad$color), 25, replace= F)

muestraMejorCalidad <- as.data.frame(buenaCalidad[filas.randomMejorCalidad,])
muestraPeorCalidad <- as.data.frame(peorCalidad[filas.randomPeorCalidad,])

length(muestraMejorCalidad$color)
length(muestraPeorCalidad$color)
```

| Calidad| Colores| Tamaño de muestra|
|:--|:--|:--|
| Buena| D, E o F| `r length(muestraMejorCalidad$color)`|
| Peor| H, I o J| `r length(muestraPeorCalidad$color)`|

En este caso dado que los tamaños de las muestras son menores a 30 se ha optado por realizar una inspección visual de los datos para ver si se asemejan a una distribución normal

```{r echo=FALSE}
ggdensity(muestraMejorCalidad$profundidad, 
          main = "Gráfico de densidad de la profundidad de la muestra A",
          xlab = "Profundidad de los diamantes")
```

```{r echo=FALSE}
ggdensity(muestraPeorCalidad$profundidad, 
          main = "Gráfico de densidad de la profundidad de la muestra B",
          xlab = "Profundidad de los diamantes")
```

**Hipótesis asumidas**

Como se puede observar ambas muestras tienen forma de campana, por lo que se puede asumir que siguen una distribución normal. Además, también se asume que las varianzas son iguales. Sin embargo, como las muestras son pequeñas no se pueden utilizar s₁  y s₂ para realizar una aproximación σ₁ y σ₂.

**Cálculo**

Una vez obtenidos estos datos se desea calcular la diferencia de promedios de profundidad entre las muestras de buena calidad y las de peor calidad con un intervalo de confianza del 95%. Para esto se hace uso de la siguiente función:

```{r}
t.test(x=muestraMejorCalidad$profundidad, y=muestraPeorCalidad$profundidad, conf.level = 0.95, var.equal = TRUE)$conf.int
```

Donde:

* **x:** primera muestra
* **y:** segunda muestra
* **conf.level:** nivel de confidencia
* **var.equal:** si las varianzas se asumen iguales

**Conclusión**

A diferencia del caso anterior, dado a que las muestras aquí son más pequeñas, se puede observar que hay tanto valores negativos como positivos, por lo cual no se puede llegar a una conclusión con certeza ya que existe la posibilidad de que ambas muestras sean iguales o que una sea mayor que otra.

## IC de una varianza
A continuación, se presenta IC de la varianza de la variable quilates del dataset diamantes.

| Muestra| Tamaño|
|:--|:--|
| A| `r length(diamantes$quilate)`|

Una vez tenemos la muestra, utilizaremos la variable de quilates para obtener el IC de varianza de la muestra, para esto utilizaremos la librería EnvStats y específicamente su método varTest que nos dará el intervalo que estamos buscando.

Antes de realizar el cálculo debemos tener en cuenta lo siguiente:

* El nivel de confianza utilizado será de 95%
* La muestra sigue una distribución normal

**Cálculo**

El código utilizado para este cálculo fue:

```{r}
P1 <- varTest(diamantes$quilate, conf.level = 0.95)$conf.int
P1
```

Donde:

* **Primer parámetro:** primera muestra
* **conf.level:** nivel de confidencia

**Conclusión**

Dando como resultado el IC del 95% para la varianza de quilates:
]`r P1`[, como podemos ver el intervalo es muy pequeño y esto se debe a que se usaron una gran cantidad de datos para realizar el cálculo, dando un resultado muy preciso.


## IC de un cociente de varianzas

Gracias a la librería stests podemos realizar el cociente de varianza de dos poblaciones, para esto dividiremos el dataset de diamantes de dos poblaciones la primera contendrá los diamantes que tengan una alta claridad, teniendo como la más baja calidad posible para esta población VS1 y una segunda población que estará compuesta por los diamantes que tengan una claridad igual o inferior a VS2.


```{r}
claridadAlta <- diamantes[diamantes$claridad == "IF" | diamantes$claridad == "VVS1" | diamantes$claridad == "VVS2" |
diamantes$claridad == "VS1",]
length(claridadAlta$quilate)

clariadadBaja <- diamantes[diamantes$claridad == "VS2" | diamantes$claridad == "SI1" | diamantes$claridad == "SI2" | 
diamantes$claridad == "I1",]
length(clariadadBaja$quilate)
```

| Calidad| Claridad| Tamaño de muestra|
|:--|:--|:--|
| Alta| IF, VVSS1, VVSS2, VS1| `r length(claridadAlta$claridad)`|
| Baja| VS2, SI1, SI2, I1| `r length(clariadadBaja$claridad)`|


Antes de realizar el cálculo debemos tener en cuenta lo siguiente:

* El nivel de confianza utilizado será de 95%.
* La población 1 y la población 2 se comportan normalmente.

**Cálculo**

El código utilizado para este cálculo fue:

```{r}
R <- stests :: var.test(claridadAlta$quilate, clariadadBaja$quilate,conf.level = 0.95)$conf.int
R
```

Donde:

* **Primer parámetro:** primera muestra
* **Segundo parámetro:** segunda muestra
* **conf.level:** nivel de confidencia

**Conclusión**

Dando como resultado:
]`r R`[

En conclusión, al resultado obtenido podemos ver que las varianzas de estas dos poblaciones no deberían ser iguales ya que el número 1 no pertenece al intervalo, también podemos decir que la varianza de la segunda población es mayor ya que ambos valores son menores que 1.

# III Parte: Análisis Inferencial (pruebas de hipótesis de una y dos poblaciones)

## Resumen de variables seleccionadas

**Una población:**

| Variables| Tipos| Descripción| Parámetro por estimar (IC)|
|:--|:--|:--|:--|
| Precio| Cuantitativa| Precio en dólares estadounidenses| Promedio usando distribución z y distribución t|
| Corte| Cualitativa| Calidad del corte (Regular, Bueno, Muy bueno, Premium, Ideal)| Proporción |
| Quilates| Cuantitativa| Peso del diamante| Varianza

**Dos poblaciones:**

| Variables| Tipos| Descripción| Parámetro por estimar (IC)|
|:--|:--|:--|:--|
| Corte| Cualitativa| Calidad del corte (Regular, Bueno, Muy bueno, Premium, Ideal)| Diferencia de proporciones|
| Profundidad| Cuantitativa| Porcentaje de la profundidad total en milímetros| Diferencia de promedios usando distribución z y t y cociente de varianzas|

## Prueba de hipótesis para un promedio usando distribución Z

Para este ejemplo se utilizarán dos grupos (los mismos utilizados para la prueba del IC para un promedio usando distribución Z). Utilizando todos los datos de la variable precio extraídos del dataset diamantes. Tal está distribuido de la siguiente manera:

```{r}
set.seed(4562) # semilla

poblacion <- as.data.frame(diamantes)
poblacion.precios <- poblacion$precio

n1 <- length(poblacion.precios)
mu1 <- mean(poblacion.precios)
var1 <- var(poblacion.precios)

n1
```

| Muestra| Tamaño| Promedio| Varianza|
|:--|:--|:--|:--|
| A| `r n1`| `r mu1`| `r var1`|

**Hipótesis asumidas**

Dado que la muestra es mayor a 30, debido a las condiciones del teorema del límite central, se puede asumir que la población sigue una distribución normal y que se puede aproximar σ₁ mediante s₁.


**Cálculo**

Sea:

* $\mu_{p}$: la media del precio de los diamantes

Y dadas las siguientes hipótesis para la prueba:

* $H_{0}: \mu_{p} = 4000$
* $H_{1}: \mu_{p} > 4000$

Una vez obtenidos estos datos se procede a realizar la prueba de hipótesis haciendo uso de las siguientes funciones:

```{r}
stests::z.test(
  x = poblacion.precios, 
  sigma2 = var(poblacion.precios), 
  mu = 4000, alternative = "greater"
)

BSDA::z.test(
  x = poblacion.precios, 
  sigma.x = sd(poblacion.precios), 
  mu = 4000, alternative = "greater"
)

PASWR2::z.test(
  x = poblacion.precios, 
  sigma.x = sd(poblacion.precios), 
  mu = 4000, alternative = "greater"
)

```

Las funciones BSDA y PASWR2 aplican para una y dos poblaciones y están compuestas de los siguientes parámetros, en donde:

* **x:** vector numérico que representa la primera muestra
* **sigma.x:** desviación estándar de x (opcional)
* **mu:** el valor de la media o la diferencia de medias en la hipótesis nula
* **alternative:** indica si la prueba es de cola izquierda (less), derecha (greater) o de dos colas (two.sided)

En cambio, las funciones de stests solo aplican para una población, la cual cuenta con los parámetros donde:

* **x:** vector numérico que representa la primera muestra
* **sigma2:** varianza de x (opcional)
* **mu:** el valor de la media o la diferencia de medias en la hipótesis nula
* **alternative:** indica si la prueba es de cola izquierda (less), derecha (greater) o de dos colas (two.sided)

**Resumen de la prueba**

| Dato| Valor|
|:--|:--|
| Valor observado| $z_{obs}=-3.9121$|
| Grados de libertad| No corresponde|
| Estadístico de prueba| $\tilde{x}_p=4000$|
| Región de aceptación| ]3904.545, $+\infty$[|
| Región de rechazo| ]$-\infty$, 3904.545[|
| Nivel de confianza| 95%|

**Conclusión**

No se encontró evidencia en contra $H_{0}$ por lo cual se puede asumir que la media de los precios de diamantes es menor o igual a 4000 dólares estadounidenses. Esto concordando también con los resultados del valor P, donde se tiene una aceptación fuerte de $H_{0}$.

## Prueba de hipótesis para un promedio usando distribución t

Para este caso se utilizarán muestras las mismas muestras del caso anterior (precio de los diamantes), pero esta vez con una muestra de 20 datos.

```{r}
## Se toman filas random para sacar del dataset
set.seed(6894)
filas.random <- sample(1:53940, 20, replace= T)

## Se generan datasets nuevos con las filas random anteriores 
muestra1 <- as.data.frame(diamantes[filas.random,])
muestra.precios <- muestra1$precio
n1 <- length(muestra.precios)
mu1 <- mean(muestra.precios)
de1 <- sqrt(var(muestra.precios))
alpha1 <- 0.05

```

| Muestra| Tamaño| Promedio| Desviación estándar|
|:--|:--|:--|:--|
| A| `r n1`| `r mu1`| `r de1`|

En este caso dado que el tamaño de la muestra es menor a 30 se ha optado por realizar una inspección visual de los datos para ver si se asemeja a una distribución normal.

```{r echo=FALSE}
ggdensity(muestra1$profundidad, 
          main = "Gráfico de densidad de la profundidad de la muestra A",
          xlab = "Precio de los diamantes")
```

**Hipótesis asumidas**

Como se puede observar, la muestra tiene forma de campana, por lo que se puede asumir que sigue una distribución normal. 

**Cálculo**

Sea:

* $\mu_{p}$: la media del precio de los diamantes

Y dadas las siguientes hipótesis para la prueba:

* $H_{0}: \mu_{p} = 4000$
* $H_{1}: \mu_{p} > 4000$

Una vez obtenidos estos datos se procede a realizar la prueba de hipótesis haciendo uso de la siguiente función:


```{r}
t.test(
  x = muestra.precios, 
  mu = 4000, alternative = "greater"
  )
```

La función está compuesta de los siguientes parámetros, en donde:

* **x:** vector numérico que representa la primera muestra
* **mu:** el valor de la media o la diferencia de medias en la hipótesis nula
* **alternative:** indica si la prueba es de cola izquierda (less), derecha (greater) o de dos colas (two.sided)

**Resumen de la prueba**

| Dato| Valor|
|:--|:--|
| Valor observado| $t_{obs}=0.55392$|
| Grados de libertad| $v=19$|
| Estadístico de prueba| $\tilde{x}_t=4000$|
| Región de aceptación| ]2664.219, $+\infty$[|
| Región de rechazo| ]$-\infty$, 2664.219[|
| Nivel de confianza| 95%|


**Conclusión**

No se encontró evidencia en contra $H_{0}$ por lo cual se puede asumir que la media del precio de los diamantes es menor o igual a 4000 dólares estadounidenses. Esto concordando también con los resultados del valor P, donde se tiene una aceptación de $H_{0}$.



## Prueba de hipótesis para una proporción

```{r include=FALSE}
library(datos)
library(stats)




gamaAlta <- diamantes[diamantes$corte == "Premium" | diamantes$corte == "Ideal",]
tamañoMuestraGama <- length(gamaAlta$corte)


exitos.alta <- gamaAlta[gamaAlta$color == "D",]
tamañoMuestraColor <-length(exitos.alta$color)



prop.test(x=length(exitos.alta$color), n=length(gamaAlta$corte), p = 0.12, alternative = "less", conf.level = 0.95)

```

Basado en la experiencia, un joyero afirma que mínimo el 12% de los diamantes de gama alta son de color tipo D.

¿Podemos aceptar la afirmación del joyero?

Para realizar la prueba, se consideran las siguientes hipótesis:

\(H_{0}:p =0.12(\geq )\)

\(H_{1}:p < 0.12\)

dónde p representa la proporción de que unos diamantes de gama alta elegidos al azar, sean de color tipo D. La prueba a realizar es de cola izquierda.

En R se está implementado la función prop.test, que además también sirve para contrastar dos proporciones por medio de muestras independientes grandes.

Su sintaxis es:

              prop.test(x, n, p = ..., alternative = ..., conf.level = ...)

donde:

* **n** es el tamaño de la muestra.
* **x** es el número de éxitos de la muestra.
* **p** es la proporción poblacional que contrastamos.
* **alternative** especifica la hipótesis alternativa, debe ser "two.sided", "greater" o "less". 
* **conf.level** es el nivel de confianza.

Para obtener el valor n se tomaron los datos del dataset "Diamantes" donde se utilizó una muestra de la variable "corte" incluyéndose todos los diamantes cuyo corte sea de tipo "Premium" o "Ideal", siendo esta una muestra de diamantes de gama alta, de la siguiente manera:


```{r}
gamaAlta <- diamantes[diamantes$corte == "Premium" | diamantes$corte == "Ideal",]
gamaAlta
tamañoMuestraGama <- length(gamaAlta$corte)
tamañoMuestraGama

```

| Gama| Corte| Tamaño de muestra|
|:--|:--|:--|
| Alta| Premium e Ideal| `r tamañoMuestraGama`| 



Para obtener el valor x se incorporó la variable color del dataset "Diamantes" para saber cuál es el número de diamantes que hay de corte "premium" o "Ideal" (que hemos llamado gama alta) de color tipo D, de la siguiente manera:

```{r}
exitos.alta <- gamaAlta[gamaAlta$color == "D",]
exitos.alta
tamañoMuestraColor <-length(exitos.alta$color)
tamañoMuestraColor
```

| Gama| Corte| Color| Tamaño de muestra|
|:--|:--|:--|:--|
| Alta| Premiun e Ideal | D| `r tamañoMuestraColor`| 


Antes de realizar las operaciones se debe verificar que np > 5 y nq > 5

Para ello tenemos los siguientes datos:

p = x/n = 4437/35342 = 0.1255446777

np = 35342 * 0.1255446777 = 4437
                                        
q = 1-p = 1 - 0.1255446777 = 0.8744553223
                                        
nq = 35342 * 0.8744553223 = 30905

                                        
Como ambos valores son mayores a 5 se procede a utilizar la función prop.test con sus respectivos valores
```{r}
prop.test(x=length(exitos.alta$color), n=length(gamaAlta$corte), p = 0.12, alternative = "less", conf.level = 0.95)
```


**Resumen de la prueba**

| Dato| Valor|
|:--|:--|
| Valor observado| $z_{obs}$ = 3.199531216|
| Grados de libertad| no corresponde|
| Estadístico de prueba| $\tilde{p}$ = 0.1255447|
| Región de aceptación| ]0.0000000, 0.1284867[|
| Región de rechazo| ]0.1284867, 1[|
| Nivel de confianza| 0.95|


**Conclusión:**

\(H_{0}\) no puede ser rechazado dado que no se encontró evidencia suficiente en contra, ya que según lo observado el 0.12 se encuentra dentro del intervalo de aceptación y el valor p es mayor que el valor de alfa, por lo que lo ubica en la región de aceptación, y por ende se asume como válida la afirmación del joyero.  

## Prueba de hipótesis para una diferencia de proporciones

```{r include=FALSE}
library(datos)
library(stats)




gamaBaja <- diamantes[diamantes$corte == "Regular" | diamantes$corte == "Bueno",]
gamaBaja

gamaAlta <- diamantes[diamantes$corte == "Premium" | diamantes$corte == "Ideal",]
gamaAlta



tamañoMGB <- length(gamaBaja$corte)
tamañoMGA <- length(gamaAlta$corte)



exitos.baja <- gamaBaja[gamaBaja$color == "D",]
exitosBaja <- length(exitos.baja$color) 

exitos.alta <- gamaAlta[gamaAlta$color == "D",]
exitosAlta <- length(exitos.alta$color)




prop.test(x = c(length(exitos.alta$color) , length(exitos.baja$color)), n = c(length(gamaAlta$corte), length(gamaBaja$corte)))
```


Para las pruebas de contraste de proporciones para muestras grandes, se utilizará la función prop.test

Su sintaxis es:

              prop.test(x, n, p = ..., alternative = ..., conf.level = ...)

donde:

* **n** es un vector de dos entradas de los respectivos tamaños de las muestras.
* **x** es el vector de dos números naturales que representan los éxitos ambas muestras.


Es este ejercicio se contrastará si la proporción de diamantes de gama alta de color tipo D es la misma que la proporción de diamantes de gama baja de color tipo D

Para realizar esta prueba, se considerarán las siguientes hipótesis:

\(H_{0}:p_{a}-p_{b} = 0\)

\(H_{1}:p_{a}-p_{b} \neq 0\)


Para obtener el valor n se tomaron dos muestras de la variable "corte", en la primera muestra se incluyen todos los diamantes cuyo corte sea de tipo "Premium" ó "Ideal" (muestra de gama alta) y la segunda muestra donde se incluyen todos los diamantes cuyo corte sea de tipo "Regular" ó  "Bueno" (muestra de gama baja), de la siguiente manera:


```{r}
gamaAlta <- diamantes[diamantes$corte == "Premium" | diamantes$corte == "Ideal",]
gamaAlta

gamaBaja <- diamantes[diamantes$corte == "Regular" | diamantes$corte == "Bueno",]
gamaBaja

tamañoMGA <- length(gamaAlta$corte)
tamañoMGA

tamañoMGB <- length(gamaBaja$corte)
tamañoMGB

```


| Gama| Corte| Tamaño de muestra|
|:--|:--|:--|
| Alta| Premium e Ideal| `r tamañoMGA`| 


| Gama| Corte| Tamaño de muestra|
|:--|:--|:--|
| Baja| Regular y Bueno| `r tamañoMGB`| 



Para obtener el valor x se incorporó la variable color del dataset "Diamantes", con el fin de calcular cuantos diamantes de gama alta y baja son de color tipo D, de la siguiente manera:

```{r}
exitos.alta <- gamaAlta[gamaAlta$color == "D",]
exitos.alta

exitos.baja <- gamaBaja[gamaBaja$color == "D",]
exitos.baja


exitosAlta <- length(exitos.alta$color)
exitosAlta

exitosBaja <- length(exitos.baja$color) 
exitosBaja
```

| Gama | Color| Tamaño de muestra|
|:--|:--|:--|
| Alta| D| `r exitosAlta`| 

| Gama | Color| Tamaño de muestra|
|:--|:--|:--|
| Baja| D| `r exitosBaja`| 




Antes de realizar las operaciones se debe verificar que np > 5 y nq > 5 para las dos poblaciones

Para ello tenemos los siguientes datos para la primera población: 

p1 = x1/n1 = 4437/35342 = 0.1255446777

n1p1 = 35342 * 0.1255446777 = 4437

q1 = 1-p1 = 1 - 0.1255446777 = 0.8744553223

n1q1 = 35342 * 0.8744553223 = 30905
  
  
Y tenemos los siguientes datos para la segunda población: 

p2 = x2/n2 = 825/6516 = 0.126611418

n2p2 = 6516 * 0.126611418 = 825

q2 = 1-p2 = 1 - 0.126611418 = 0.873388582

n2q2 = 6516 * 0.873388582 = 5691
  

                                        
Como ambos valores son mayores a 5 se procede a utilizar la función prop.test con sus respectivos valores
```{r}
prop.test(x = c(length(exitos.alta$color) , length(exitos.baja$color)), n = c(length(gamaAlta$corte), length(gamaBaja$corte)))
```


**Resumen de la prueba**

| Dato| Valor|
|:--|:--|
| Valor observado| $z_{obs}$ = -0.0010667|
| Grados de libertad| No corresponde|
| Estadístico de prueba| $\tilde{p_1}$ - $\tilde{p_2}$ = 0|
| Región de aceptación| ]-0.009939703, 0.007806222[|
| Región de rechazo| ]-1, -0.009939703[ $\cup$ ]0.007806222, +1[|
| Nivel de confianza| 0.95|


**Conclusión:**

\(H_{0}\) no puede ser rechazado dado que no se encontró evidencia suficiente para rechazarlo, ya que según lo observado el 0 se encuentra dentro del intervalo de aceptación y el valor p es mayor que el valor de alfa por lo que lo ubica en la región de aceptación, y por ende se asume que la proporción de diamantes de gama alta con color de tipo D se puede considerar similar a la proporción de diamantes de gama baja con color de tipo D.   

## Prueba de hipótesis para una diferencia de promedios usando distribución z

Para este ejemplo se utilizarán dos grupos (los mismo utilizados para la prueba del IC). En primer lugar, está el grupo de diamantes que se considera que tienen un color de buena calidad, este grupo está compuesto de aquellos diamantes cuyo color es "D", "E" o "F". Luego se tiene el grupo diamantes cuyo color es de peor calidad, el cual está compuesto por los diamantes con colores "H", "I" o "J". Ambos grupos están distribuidos de la siguiente manera:

```{r}
buenaCalidad <- diamantes[diamantes$color == "D" | diamantes$color == "E" | diamantes$color == "F",]
peorCalidad <- diamantes[diamantes$color == "H" | diamantes$color == "I" | diamantes$color == "J",]

length(buenaCalidad$color)
length(peorCalidad$color)
```

| Calidad| Colores| Tamaño de muestra|
|:--|:--|:--|
| Buena| D, E o F| `r length(buenaCalidad$color)`|
| Peor| H, I o J| `r length(peorCalidad$color)`|

**Hipótesis asumidas**

Dado que ambas muestras son mayores a 30 se puede asumir que ambas siguen una distribución normal y que se puede aproximar σ₁ y σ₂ mediante s₁  y s₂. Además, ambos grupos son independientes.

**Cálculo**

Sea:

* $\mu_{b}$: la media de la profundidad de los diamantes de buena calidad
* $\mu_{m}$: la media de la profundidad de los diamantes de peor calidad

Y dadas las siguientes hipótesis para la prueba:

* $H_{0}: \mu_{b} - \mu_{m} = 0$
* $H_{1}: \mu_{b} - \mu_{m} > 0$

Una vez obtenidos estos datos se procede a realizar la prueba de hipótesis haciendo uso de las siguientes funciones:

```{r}
BSDA::z.test(x = buenaCalidad$profundidad, y = peorCalidad$profundidad, sigma.x = sd(buenaCalidad$profundidad), sigma.y = sd(peorCalidad$profundidad), mu = 0, alternative = "greater")
PASWR2::z.test(x = buenaCalidad$profundidad, y = peorCalidad$profundidad, sigma.x = sd(buenaCalidad$profundidad), sigma.y = sd(peorCalidad$profundidad), mu = 0, alternative = "greater")
```

Ambas funciones aplican para una y dos poblaciones y están compuestas de los siguientes parámetros, en donde:

* **x:** vector numérico que representa la primera muestra
* **y:** vector numérico que representa la segunda muestra (opcional)
* **sigma.x:** desviación estándar de x (opcional)
* **sigma.y:** desviación estándar de y (opcional)
* **mu:** el valor de la media o la diferencia de medias en la hipótesis nula
* **alternative:** indica si la prueba es de cola izquierda (less), derecha (greater) o de dos colas (two.sided)

**Resumen de la prueba**

| Dato| Valor|
|:--|:--|
| Valor observado| $z_{obs} = -11.432$|
| Grados de libertad| No corresponde|
| Estadístico de prueba| $\tilde{x}_b$ - $\tilde{x}_m$ = 0|
| Región de aceptación| ]-0.1889905, +$\infty$[|
| Región de rechazo| ]-$\infty$, -0.1889905[|
| Nivel de confianza| 0.95|

**Conclusiones**

No se encontró evidencia en contra $H_{0}$ por lo cual se puede asumir que la media de la profundidad de diamantes con color de mejor calidad es menor a la de los diamantes con color de peor calidad. Esto concordando también con los resultados del valor P, donde se tiene una aceptación fuerte de $H_{0}$.

## Prueba de hipótesis para un cociente de varianzas

Para este caso se utilizarán muestras aleatorias sin reemplazo de tamaño 25 de los dos mismos grupos utilizados en cálculo del IC para diferencia de promedios con distribución t (diamantes con color de buena calidad y diamantes con color de peor calidad).

```{r}
# Se sacan los datos de la calidad
buenaCalidad <- diamantes[diamantes$color == "D" | diamantes$color == "E" | diamantes$color == "F",]
peorCalidad <- diamantes[diamantes$color == "H" | diamantes$color == "I" | diamantes$color == "J",]

# Se toman las filas para las muestras aleatorias
set.seed(6894)
filas.randomMejorCalidad <- sample(1:length(buenaCalidad$color), 25, replace= F)
filas.randomPeorCalidad <- sample(1:length(peorCalidad$color), 25, replace= F)

muestraMejorCalidad <- as.data.frame(buenaCalidad[filas.randomMejorCalidad,])
muestraPeorCalidad <- as.data.frame(peorCalidad[filas.randomPeorCalidad,])

length(muestraMejorCalidad$color)
length(muestraPeorCalidad$color)
```

| Calidad| Colores| Tamaño de muestra|
|:--|:--|:--|
| Buena| D, E o F| `r length(muestraMejorCalidad$color)`|
| Peor| H, I o J| `r length(muestraPeorCalidad$color)`|

Previamente ya se había realizado una prueba de normalidad de estas muestras en el cálculo del IC para diferencia de promedio, sin embargo, aquí se adjunta la prueba de nuevo:

```{r echo=FALSE}
ggdensity(muestraMejorCalidad$profundidad, 
          main = "Gráfico de densidad de la profundidad de la muestra A",
          xlab = "Profundidad de los diamantes")
```

```{r echo=FALSE}
ggdensity(muestraPeorCalidad$profundidad, 
          main = "Gráfico de densidad de la profundidad de la muestra B",
          xlab = "Profundidad de los diamantes")
```

**Hipótesis asumidas**

* El nivel de confianza utilizado será de 95%.
* La población 1 y la población 2 se comportan normalmente.

**Cálculo**

Sea:

* $\sigma^{2}_{b}$: la media de la profundidad de los diamantes de buena calidad
* $\sigma^{2}_{m}$: la media de la profundidad de los diamantes de peor calidad

Y dadas las siguientes hipótesis para la prueba:

* $H_{0}: \frac{\sigma^{2}_{b}}{\sigma^{2}_{m}} = 1$
* $H_{1}: \frac{\sigma^{2}_{b}}{\sigma^{2}_{m}} ≠ 0$

Una vez obtenidos estos datos se procede a realizar la prueba de hipótesis haciendo uso de la siguiente función:

```{r}
stests::var.test(x = muestraMejorCalidad$profundidad, y = muestraPeorCalidad$profundidad)
```

Donde:

* **x:** primera muestra
* **y:** segunda muestra (opcional)
* **alternative:** si es de cola derecha, doble cola o cola izquierda (opcional)
* **null.value:** por defecto es 1 considerando que la relación entre las varianzas es 1. (opcional)
* **conf.level:** nivel de confidencia (opcional)

**Resumen de la prueba**

| Dato| Valor|
|:--|:--|
| Valor observado| $f_{obs} = 2.8255$|
| Grados de libertad| $v_{b} = 24$ $v_{m} = 24$|
| Estadístico de prueba| $\frac{s^{2}_{b}}{s^{2}_{m}}=0$|
| Región de aceptación| ]1.245114, 6.411864[|
| Región de rechazo| ]-$\infty$, 1.245114[$\cup$]6.411864, +$\infty$[|
| Nivel de confianza| 0.95|

**Conclusiones**

Se llegó a encontrar evidencia contra $H_{0}$ por lo cual se puede asumir que la varianza de la profundidad de diamantes con color de mejor calidad es distinta a la de los diamantes con color de peor calidad. Esto concordando también con los resultados del valor P, donde se tiene un rechazo fuerte de $H_{0}$.


## Prueba de hipótesis para una diferencia de promedios usando distribución t

Para este caso se utilizarán muestras las mismas muestras del ejemplo anterior (diamantes con color de buena calidad y diamantes con color de peor calidad).

```{r}
# Se sacan los datos de la calidad
buenaCalidad <- diamantes[diamantes$color == "D" | diamantes$color == "E" | diamantes$color == "F",]
peorCalidad <- diamantes[diamantes$color == "H" | diamantes$color == "I" | diamantes$color == "J",]

# Se toman las filas para las muestras aleatorias
set.seed(6894)
filas.randomMejorCalidad <- sample(1:length(buenaCalidad$color), 25, replace= F)
filas.randomPeorCalidad <- sample(1:length(peorCalidad$color), 25, replace= F)

muestraMejorCalidad <- as.data.frame(buenaCalidad[filas.randomMejorCalidad,])
muestraPeorCalidad <- as.data.frame(peorCalidad[filas.randomPeorCalidad,])

length(muestraMejorCalidad$color)
length(muestraPeorCalidad$color)
```

| Calidad| Colores| Tamaño de muestra|
|:--|:--|:--|
| Buena| D, E o F| `r length(muestraMejorCalidad$color)`|
| Peor| H, I o J| `r length(muestraPeorCalidad$color)`|

**Hipótesis asumidas**

Por el ejemplo anterior se puede asumir que ambas muestras siguen una distribución normal y que las varianzas son distintas.

**Cálculo**

Sea:

* $\mu_{b}$: la media de la profundidad de los diamantes de buena calidad
* $\mu_{m}$: la media de la profundidad de los diamantes de peor calidad

Y dadas las siguientes hipótesis para la prueba:

* $H_{0}: \mu_{b} - \mu_{m} = 0$
* $H_{1}: \mu_{b} - \mu_{m} > 0$

Una vez obtenidos estos datos se procede a realizar la prueba de hipótesis haciendo uso de las siguientes funciones:

```{r}
t.test(x = muestraMejorCalidad$profundidad, y = muestraPeorCalidad$profundidad, mu = 0, alternative = "greater", var.equal = F)
```

La función está compuesta de los siguientes parámetros, en donde:

* **x:** vector numérico que representa la primera muestra
* **y:** vector numérico que representa la segunda muestra (opcional)
* **mu:** el valor de la media o la diferencia de medias en la hipótesis nula
* **alternative:** indica si la prueba es de cola izquierda (less), derecha (greater) o de dos colas (two.sided)
* **var.equal** indica si las varianzas se asumen iguales

**Resumen de la prueba**

| Dato| Valor|
|:--|:--|
| Valor observado| $t_{obs} = -0.64071$|
| Grados de libertad| 39|
| Estadístico de prueba| $\tilde{x}_b$ - $\tilde{x}_m$ = 0|
| Región de aceptación| ]-0.7404251, +$\infty$[|
| Región de rechazo| ]-$\infty$, -0.7404251[|
| Nivel de confianza| 0.95|

**Conclusiones**

No se encontró evidencia en contra $H_{0}$ por lo cual se puede asumir que la media de la profundidad de diamantes con color de mejor calidad es menor a la de los diamantes con color de peor calidad. Esto concordando también con los resultados del valor P, donde se tiene una aceptación fuerte de $H_{0}$.

## Prueba de hipótesis para una varianza

Para este caso de hipótesis se estará usando como muestra la variable de quilates del dataset diamantes

```{r}
quilates <- diamantes$quilate
```
| Muestra| Tamaño|
|:--|:--|
| Quilates| `r length(quilates)`|

**Hipótesis asumidas**

Antes de realizar el cálculo es importante asumir que la muestra sigue una distribución normal

**Cálculo**

Sea:

* $\sigma^2$: la varianza de la variable quilates de la muestra

Y dadas las siguientes hipótesis para la prueba:

* $H_{0}: \sigma =\sqrt{0.2246867} = 0.47401$
* $H_{1}: \sigma ≠ 0.47401$

Una vez obtenidos estos datos se procede a realizar la prueba de hipótesis haciendo uso de las siguientes funciones:

```{r}
sigma.test(x = quilates, sigma = 0.47401, alternative = "two.sided", conf.level = 0.95)
```

La función está compuesta de los siguientes parámetros, en donde:

* **x:** vector numérico que representa la primera muestra
* **sigma:** es la desviación estándar de la muestra
* **alternative:** indica si la prueba es de cola izquierda (less), derecha (greater) o de dos colas (two.sided)
* **conf.level:** Indica el nivel de confianza con el que se realiza la prueba

**Resumen de la prueba**

| Dato| Valor|
|:--|:--|
| Valor observado| $𝒳^{2}_{obs} = 53939$|
| Grados de libertad| $v = 53939$|
| Estadístico de prueba| $s^{2} = 0.2246867$|
| Región de aceptación| ]0.2220290, 0.2273925[|
| Región de rechazo| ]-$\infty$, 0.2220290[ $\cup$ ]0.2273925, +$\infty$[|
| Nivel de confianza| 0.95|

**Conclusiones**

No se encontró evidencia en contra de $H_{0}$ por lo cual se puede asumir que la varianza de la muestra si es de 0.2246867, esto debido a que el valor de p es muy cercano a 1 y porque qué valor dado por la función sobre la varianza muestral si se encuentra entre el intervalo ]0.2220290, 0.2273925[

# IV Parte: Otras pruebas de hipótesis en R

## Caso 1:

Para este caso se utilizará la base de datos KidsFeet del paquete mosaicData:

```{r}
str(KidsFeet)
```

```{r}
feetsplit <- split(KidsFeet$length, KidsFeet$sex)

str(feetsplit)
```
Como pudimos observar, la función split dividió la base de datos en dos, con B para los niños y G para las niñas, se procederá a almacenarla en las siguientes variables:

```{r}
boys.feets <- feetsplit$B
girls.feets <- feetsplit$G
```

1. Gráficos

Debido a que los tamaños de las muestras de los niños es de 20 y el de las niñas de 19, se pueden crear distinas gráficas para determinar si dicha muestra sigue una distribución normal.A continuación se presentan los gráficos de densidad 

```{r}
ggdensity(
  boys.feets, 
  main = "Gráfico de densidad de los niños",
  xlab = "Tamaño del largo de los pies en centímetros"
)
```

```{r}
ggdensity(
  girls.feets, 
  main = "Gráfico de densidad de las niñas",
  xlab = "Tamaño del largo de los pies en centímetros"
)
```

```{r}
mean(boys.feets)
mean(girls.feets)
```

**¿Se puede intuir una posible normalidad para los datos?**

Como se puede observar, probablemente exista normalidad en ambas muestras de datos, ya que parece ser que la gráfica tiene forma de campana, además, en ambos casos la punta de la gráfica se encuentra muy cerca de la media.


2. Gráfico QQ-plot

A continuación se presentan los gráficos de QQ-plot;

```{r}
qqnorm(boys.feets, ylab = "Largo del pie", main = "Gráfico QQ Plot de los niños")
qqline(boys.feets)
```
```{r}
qqnorm(girls.feets, ylab = "Largo del pie", main = "Gráfico QQ Plot de las niñas")
qqline(girls.feets)
```

En ambos casos, parece ser que el conjunto de datos no parece seguir una distribución normal, especialmente cerca de las colas.

3. Pruebas formales de normalidad S-W test, A-D test, K-S-L test

**Test de Shapito-Wilks o S-W test**

```{r}
boys.sw <- shapiro.test(boys.feets)
boys.sw

girls.sw <- shapiro.test(girls.feets)
girls.sw
```
Para ambos casos, no se encontró evidencia en contra para asumir normalidad, debido a que el valor p es mayor que el nivel de significancia (0.05).

**Test de normalidad de Anderson-Darling o A-D test**

```{r}
boys.ad <- ad.test(boys.feets)
boys.ad

girls.ad <- ad.test(girls.feets)
girls.ad
```
En ambos casos, no se encontró evidencia en contra para asumir normalidad, debido a que el valor p es mayor que el nivel de significancia (0.05).

**Test de Kolmogorov-Smirnov-Lilliefors o K-S-L test**

```{r}
boys.ksl <- lillie.test(boys.feets)
boys.ksl

girls.ksl <- lillie.test(girls.feets)
girls.ksl
```
En ambos casos, no se encontró evidencia en contra para asumir normalidad, debido a que el valor p es mayor que el nivel de significancia (0.05).

4. D'Agostino-Pearson

Para realizar esta prueba, es necesario saber que el tamaño de la muestra obligatoriamente debe de ser de tamaño 20 o superior, por ende, no es posible realizar la prueba para el caso del tamaño de las niñas debido a que dicha muestra es de tamaño 19. Sabiendo esto, se procede a realizar la prueba para el tamaño de la muestra en general y luego para la muestra de los niños:

```{r}
dagoTest(KidsFeet$length)
boys.dap <- dagoTest(boys.feets)
boys.dap
```
No se encontró evidencia en contra para asumir normalidad, debido a que el valor p general (Omnibus) es mayor que el nivel de significancia (0.05).

5. Análisis de custoris y simetría de los datos

A continuación se mostrarán los análisis de custoris en niños y niñas para el tamaño de la planta del pie:

```{r}
boys.kurtosis <- moments::kurtosis(boys.feets) # curtosis en niños
boys.kurtosis

girls.kurtosis <- moments::kurtosis(girls.feets) # curtosis en niñas
girls.kurtosis
```

Como podemos observar, ambos resultados fueron mayores que cero, por lo que se puede concluir que ambos tienden a ser leptocúrtica, es decir, su campana es alargada y muy punteada, con unas colas muy bajas.

A continuación se mostrarán los análisis de simetría en niños y niñas para el tamaño de la planta del pie:

```{r}
boys.skewness <- moments::skewness(boys.feets) # simetria en niños
boys.skewness

girls.skewness <- moments::skewness(girls.feets) # simetria en niñas
girls.skewness
```

De la simetría se puede concluir que ambas gráficas son simétricas, aunque en el caso de los niños, al ser positivo, su media está un poco más inclinada hacia la izquierda, y en las niñas ocurre lo contrario, al ser negativo pero acercándose a 0, su media está ligeramente más inclinada hacia la derecha.


## Caso 2:

Para este caso se utilizará la base de datos medidas_cuerpo de la siguiente url:

```{r}
url <- 'https://raw.githubusercontent.com/fhernanb/datos/master/medidas_cuerpo' 
body <- read.table(file=url, header=T)

str(body)
```

```{r}
biceps <- body$biceps
str(biceps)
```

1. Gráficos

A continuación se presentan los gráficos de densidad para el tamaño de los biceps:

```{r}
ggdensity(
  biceps, 
  main = "Gráfico de densidad de los biceps",
  xlab = "Tamaño del largo de los biceps en centímetros"
)
```

Se puede observar que la gráfica no tiene forma de campana y cerca de la media no existe un punto máximo, por lo que se concluye que dicha muestra no sigue una distribución normal.

2. Gráfico QQ-plot

A continuación se presentan los gráficos de QQ-plot, es importante saber que se utilizarán las edades para que así el gráfico del tamaño de los biceps tenga sentido:

```{r}
#qqplot(biceps, body$edad, xlab = "Tamaño de los biceps", ylab = "Edad de la persona", main = "Gráfico QQ Plot de los biceps")
qqnorm(biceps, ylab = "Tamaño de los biceps", main = "Gráfico QQ Plot del tamaño de los biceps")
qqline(biceps)
```

Se puede observar que el conjunto de datos no parece seguir una distribución normal, especialmente en las colas y en el centro de la gráfica.

3. Pruebas formales de normalidad S-W test, A-D test, K-S-L test

**Test de Shapito-Wilks o S-W test**

```{r}
biceps.sw <- shapiro.test(biceps)
biceps.sw
```

Se encontró evidencia en contra para asumir normalidad, debido a que el valor p es menor que el nivel de significancia de 0.05.

**Test de normalidad de Anderson-Darling o A-D test**

```{r}
biceps.ad <- ad.test(biceps)
biceps.ad
```
Se encontró evidencia en contra para asumir normalidad, debido a que el valor p es menor que el nivel de significancia de 0.05.

**Test de Kolmogorov-Smirnov-Lilliefors o K-S-L test**

```{r}
biceps.ksl <- lillie.test(biceps)
biceps.ksl
```
Se encontró evidencia en contra para asumir normalidad, debido a que el valor p es menor que el nivel de significancia de 0.05.

4. D'Agostino-Pearson

```{r}
biceps.dap <- dagoTest(biceps)
biceps.dap
```
Se encontró evidencia en contra para asumir normalidad, debido a que el valor p general (Omnibus) es menor que el nivel de significancia de 0.05.

5. Análisis de custoris y simetría de los datos

A continuación se mostrarán el análisis de custoris para el tamaño de los biceps:

```{r}
biceps.kurtosis <- moments::kurtosis(biceps) # curtosis de los biceps
biceps.kurtosis
```

Como se puede observar, el resultado fue mayor a cero, por lo que se puede concluir que tiende a ser leptocúrtica, es decir, su campana es alargada y muy punteada, con unas colas muy bajas.

A continuación se mostrará el análisis de simetría para el tamaño de los biceps:

```{r}
biceps.skewness <- moments::skewness(biceps) # simetria en medida de biceps
biceps.skewness
```

De la simetría se puede concluir la gráficas es simétrica, aunque, al ser positivo, su media está un poco más inclinada hacia la izquierda.

## Resumen casos 1 y 2

| Tipo de prueba| Niños| Niñas| Medidas de biceps|
|:--|:--|:--|:--|
| Función de densidad versus curva normal| Parece tener forma de campana| Parece tener forma de campana| No tiene forma de campana|
| Conclusión| Se concluye que sigue una dist. normal| Se concluye que sigue una dist. normal| Se concluye que no sigue una dist. normal|
| QQ-Plot| En las colas y el centro de la gráfica los datos están más alejados de la linea.| En las colas y el centro de la gráfica los datos están más alejados de la linea.| En las colas y el centro de la gráfica los datos están más alejados de la linea.|
| Conclusión| No parece seguir una distribución normal| No parece seguir una distribución normal| No parece seguir una distribución normal|
| S-W test| Valor P=`r round(boys.sw$p.value, 4)`| Valor P=`r round(girls.sw$p.value, 4)`| Valor P=`r round(biceps.sw$p.value, 4)`|
| Conclusión| Se asume normalidad; valor p > 0.05 (significancia)| Se asume normalidad; valor p > 0.05 (significancia)| NO se asume normalidad; valor p < 0.05 (significancia)|
| A-D test| Valor P=`r round(boys.ad$p.value, 4)`| Valor P=`r round(girls.ad$p.value, 4)`| Valor P=`r round(biceps.ad$p.value, 4)`|
| Conclusión| Se asume normalidad; valor p > 0.05 (significancia)| Se asume normalidad; valor p > 0.05 (significancia)| NO se asume normalidad; valor p < 0.05 (significancia)|
| D'Agostino-Pearson| Valor P=0.7267| Valor P=NA| Valor P=0.00108|
| Conclusión| Se asume normalidad; valor p > 0.05 (significancia)| No aplica, n=19 y se requiere mínimo 20| NO se asume normalidad; valor p < 0.05 (significancia)|
| Curtosis y simetría| `r round(boys.kurtosis, 4)` y `r round(boys.skewness, 4)`| `r round(girls.kurtosis, 4)` y `r round(girls.skewness, 4)`| `r round(biceps.kurtosis, 4)` y `r round(biceps.skewness, 4)`|
| Conclusión| Leptocúrtica y simétrica| Leptocúrtica y simétrica| Leptocúrtica y simétrica|
| Conclusión general sobre normalidad de los datos| Se asume normalidad ya que a pesar de que gráficamente no lo parezca, el valor p es un dato más acertado que el factor visual| Se asume normalidad ya que a pesar de que gráficamente no lo parezca, el valor p es un dato más acertado que el factor visual| NO se asume normalidad|

## Caso 3:

La siguiente tabla resume los datos de obtenidos de víctimas de crímenes elegidas al azar (según datos del Departamento de Justicia de USA):

| Descripción| HOMICIDIO| ROBO| ASALTO|
|:--|:--|:--|:--|
| **El criminal era un extraño**| 12| 379| 727|
| **El criminal era un conocido o pariente**| 39| 106| 642|

Con los datos anteriores, ¿sería posible considerarque el tipo de delito es independiente de la condición del delincuente?, o por el contrario, ¿existe alguna relación entre el tipo de delito con respecto al quien comete el acto? Se asumen un nivel de significancia de 5%.

Para este caso se plantea una prueba de independencia con las siguientes hipótesis:

\(H_{0}:\):| El tipo de delito es independiente de la condición del delincuente

\(H_{1}:\):| No existe independencia entre el tipo de delito y la condición del delicuente



Para las pruebas de independencia se utilizará la función chisq.test

Su sintaxis es:

          chisq.test(matrix(c(valores matriz), tamaño matriz))




Y se procede a utilizar la función chisq.test con los respectivos valores de la matriz que se presentó al inicio y su tamaño el cual es 2x3 (2 filas y 3 columnas)

```{r}

chisq.test(matrix(c(12,379,727,39,106,642),2,3,byrow = TRUE))

```


**Resumen de la prueba**


| Dato| Valor|
|:--|:--|
| Tipo de prueba:| Independencia|
| Valor observado| 119.33|
| Grados de libertad| 2,  representan el total de filas -1 multiplicado por el total de columnas -1|                 
| Valor P|   2.2e-16|               
| \(H_{0}:\):| El tipo de delito es independiente de la condición del delincuente|       
| \(H_{1}:\):| No existe independencia entre el tipo de delito y la condición del delicuente|


**Conclusión**

Se cuenta con sufuciente evidencia para rechazar \(H_{0}\) ya que el valor p es muy cercano a 0, por lo tanto no se puede aceptar independencia del tipo de delito con respecto a la condición del delincuente


## Caso 4:

Considerando la siguiente situación

La seguridad de los automóviles se determina mediante diversas pruebas. Una de ellas  consiste en hacer chocar un automóvil contra una barrera fija a 35 𝑚𝑖/ℎ con un maniquí colocado en el asiento del conductor.
A una de las medidas utilizadas para cuantificar el impacto del choque sobre el conductor se le conoce como **Desaceleración de pecho** y se mide en unidades de fuerza de gravedad (𝑔). Los valores más grandes indican mayores cantidades de desaceleración, las cuáles pueden provocar lesiones graves en los conductores. La siguiente tabla muestra mediciones de desaceleraciones de pecho obtenidas a partir de pruebas de choques de diferentes tipos de vehículos:

| Autos compactos| Autos medianos| Autos grandes|
|:--|:--|:--|
| 44| 41| 32|
| 43| 49| 37|
| 44| 43| 38|
| 54| 41| 45|
| 38| 47| 37|
| 43| 44| 33|
| 42| 37| 38|
| 45| 34| 45|
| 50|   | 43|
|   |   | 42|

Con los datos anteriores, ¿es posible considerar que el tamaño del automóvil puede variar en cuanto a la seguridad de sus pasajeros o por el contrario, es igualmente riesgoso? Se asume un nivel de significancia del 5%.


Para este caso se plantean las siguientes hipótesis:

Sea:

X: las unidades de fuerza de gravedad para cuantificar el impacto del choque (Variable cuantitiativa)

Y: tipos de autos utilizados en las pruebas de choque (Variable cualitativa)

μ1,μ2 y μ3 respectivamente las unidades de fuerza de gravedad promedio en los choques de cada tipo de auto.

\(H_{0}:\):μ1=μ2=μ3.

\(H_{1}:\): al menos dos de las medias no son iguales.


Creamos un archivo csv con los datos de la tabla anterior y lo cargamos en la variable "datos" 

```{r}
library(readr)

datos <- read.csv("caso4.csv", sep = ";") 
head(datos, 5)

```


Aplicamos la prueba de varianza con la funcion aov y datos del csv (el summary es para hacer un resumen de los resultados):

```{r}
summary(aov(gravedad ~ autos, data = datos))
```



**Resumen de la prueba**


| Dato| Valor|
|:--|:--|
| Tipo de prueba:| ANOVA|
| Valor observado| 3.552|
| Grados de libertad autos| 2,  cantidad de tipos de autos - 1|  
| Grados de libertad residuals| 24,  representan el total de filas(datos de fuerza de gravedad) -1 |  
| SSE| 535.6|
| SSA| 158.5|
| SST| 694.1|
| S1| 79.26|
| S2| 22.31|
| Valor P|   0.0445|               
| \(H_{0}:\):| μ1=μ2=μ3|       
| \(H_{1}:\):| al menos dos de las medias no son iguales|


**Conclusión**

En esta prueba el p-valor está dado por el resultado Pr(>F), que en este caso al ser menor que α, se rechaza la hipótesis nula, la cual indica que μ1,μ2 y μ3 son iguales, por lo que si es posible asegurar que el tamaño del automovil puede variar en cuanto a la seguridad de sus pasajeros


**4.2**

Para decir en cuáles tipos de autos existe una verdadera diferencia significativa realizaremos una prueba Tuckey

Para despejar esta duda, se recomienda utilizar la prueba Tuckey que permite calcular la diferencia de impacto de cada valor en cada variable independiente. La prueba Tuckey la realizamos de la siguiente manera:


```{r}
# Almacenamos la prueba de ANOVA en una nueva variable
AnovaCaso4 <- aov(gravedad ~ autos, data = datos)

#Pasamo la prueba ANOVa a la prueba Tuckey
TukeyHSD(AnovaCaso4)
```
Del resumen anterior, debe comprenderse lo siguiente:

diff: corresponde a la resta de los promedios muestrales entre las dos categorías comparadas

lwr: extremo izquierdo del IC

upr: extremo derecho del IC

p adj: valorP ajustado (para efectos prácticos, el valor P de la prueba)


**Conclusion**

La prueba muestra que hay una diferencia significativa entre autos  "grandes" y "compactos" donde valorP=0.0351275 < α=0.05, no así en el resto de comparaciones. 


# V Parte: Modelos de regresión lineal

## Caso 5:

Primeramente se cargan los datos de **EdadPesoGrasas.txt** como se muestra a continuación:

```{r}
grasas <- read.table('http://verso.mat.uam.es/~joser.berrendero/datos/Eda
dPesoGrasas.txt', header = TRUE)
```

Con estos datos se proceden a realizar los siguientes puntos de un análisis de regresión lineal:

### 1. Analisis de correlación entre todas la variables.

Para esto se hace uso de la función cor del paquete stats de R, con la cual se puede resumir de manera muy sencilla todos los posibles casos de correlación en una matriz:

```{r}
c <- cor(grasas)
c
```

Adicional a esta matriz, también se puede hacer uso de la función corrplot del paquete del mismo nombre. Esta función permite representar los datos de la matriz anterior de una manera más intuitiva.

```{r}
corrplot(c)
```

De este gráfico se puede observar que conforme los datos están más lejos 0 los cículos son más grandes, esto indica que existe una correlación entre las variables. En caso de que el color sea azul significa que es una correlación positiva y si es rojo es una correlación negativa. Por ejemplo en el caso de las variables edad y grasas se tiene que hay correlación positiva que indica que el aumento de una se debe en gran parte debido a la otra.

### 2. Genración de modelo RLS de mejor ajuste para dos variables con mayor coeficiente de correlación

Para este punto se hará uso de la variables edad y grasas que fueron las que tuvieron un mayor coeficiente de variación según los datos del punto anterior.

De esto se tiene que grasas será la variable Y de respuesta y que edad será la la variable X explicativa. A partir de estos datos se procede a generar el RLS haciendo uso de la función lm del paquete stats de R

```{r}
modelo <- lm(grasas ~ edad, data = grasas)
modelo
```

De esto se tiene que el modelo de RLS sería grasas = 102.575 + 5.321*edad

### 3. Análisis de la calidad del modelo generado

Para esto se hará uso del coeficiente de correlación y el coeficiente de determinación. Se utilizará la función summary para extraer el parámetro r.squared del modelo cálculado previamente y posteriormente se hará el análisis de los coeficientes.

```{r}
## Cálculo del coeficiente de determinación
summary(modelo)$r.squared

## Cálculo del coeficiente de correlación
sqrt(summary(modelo)$r.squared)
```

Se tiene que $R = 0.8373534$, esto significa que la correlación lineal entre grasas y edad es positiva y moderada. Por otra parte, se tiene que $R^{2} = 0.7011607$, de esto se interpreta que el 70.11% de variación en las grasas se debe a la edad y el restante 29.89% es por otros factores.

De todo esto se puede llegar a la conclusión de que el modelo tiene una calidad de moderada ya que hay un buen porcentaje otros factores que explican la variación de grasas y además el nivel de correlación no supera el 90%.

### 4. Gráfico de dispersión y recta de mejor ajuste

En este punto se genera un gráfico de RLS mediante el uso de la función geom_point del paquete ggplot2 de R:

```{r}
graficoGrasas <- ggplot(grasas, aes(edad, grasas))
graficoGrasas + geom_point(alpha = 0.4) + geom_smooth(method = "lm")
```

Para un IC del 95% se puede visualizar que la calidad del modelo se encuentra en un nivel moderado, ya que a pesar de que hay varios puntos dentro de la zona del IC hay una cantidad similar que se encuentran por fuera. Esto concordando también con lo visualizado mediante los coeficiente de correlación y determinación.

### 5. Prueba de normalidad de residuos

Con el fin de verificar si el los datos pueden ajustarse de manera lineal, se procede a realizar una prueba para verificar si la distribución de los errores o residuos se comporta de manera normal. Para ello se hace uso de la función lillie.test del paquete nortest de R.

```{r}
b0 <- 102.575
b1 <- 5.321

grasas.estimada <- b0 + b1 * grasas$edad
errores <- grasas.estimada - grasas$grasas
lillie.test(errores)
```

Como el valor P es grande, no existe evidencia suficiente para rechazar la normalidad de los errores, por lo tanto se puede asumir la normalidad de los mismos, por lo que se cumple el principio.

### 6. Intervalo de confianza de 95% para los coeficientes del modelo

Con el objetivo de hallar los IC de los parametos $\beta_0$ y $\beta_1$, se hace uso de la función confint del paquete stats:

```{r}
confint(modelo,level = 0.95)
```

Entonces se tiene que $\beta_0$ está entre ]41.265155, 163.885130[ y $\beta_1$ ]3.822367, 6.818986[

### 7. Para una edad de 27 años, se determinará un IC de 95% para 𝜇𝑌|𝑥=27 y un intervalo de predicción para los valores de Y asociados a dicha edad.

Para el cálculo de estos dos parámetros se hace uso de la función predict.lm del paquete stats, la cual funciona tanto para intervalos de confidencia como de predicción.

Primero se calcula el intervalo de confidencia:

```{r}
x0 <- data.frame(edad = 27)
predict.lm(modelo, x0, interval = "confidence", level = 0.95)
```

Y se tiene que se encuentra entre ]220.6777, 271.7891[ con un nivel de confianza del 95%. Y significa que se espera que la media de grasa para una edad de 27 años se encuentre en ese intervalo el 95% de las veces.

Luego se calcula el intervalo de predicción:

```{r}
x0 <- data.frame(edad = 27)
predict.lm(modelo, x0, interval = "prediction", level = 0.95)
```

Y se tiene que el intervalo de predicción con IC del 95% es ]152.7653, 339.7015[, lo que significa que se espera que el valor de grasa para una edad de 27 años se encuentre en ese intervalo el 95% de las veces.

### 8. Verificación de la linealidad entre las variables y de dependencia lineal entre estas.

Primero se tiene las siguientes hipótesis:

* $H_0: \beta=0$ (no hay linealidad)
* $H_1: \beta≠0$

Para probar la siguiente hipótesis se hará uso de de la función summary, esto con el obtener un resumen de los datos del modelo.

```{r}
summary(modelo)
```

Como en la pendiente el valor P es menor a 0.05 se rechaza $H_0$ por lo que se puede asumir que la pendiente es distinta de 0 lo que significa que hay linealidad y que hay dependencia lineal entre las variables grasas y edad.

## Caso 6:

```{r}
ventasdb <- read.csv("DatosVentas.csv", , header = TRUE)
ventasdb
```

**Generación de los modelos**

##Regresion Lineal Simple
#1
```{r}
mod0 <- lm(ventas ~ tv, data = ventasdb)
mod0
```
Tras generar el modelo optenemos la ecuación:

ventas = 7.03259 + 0.04754 * tv

##Regresion Lineal Multiple
#2
```{r}
mod1 <- lm(ventasdb$ventas ~ ventasdb$tv+ventasdb$radio+ventasdb$periodico)
mod1
```
Tras generar el modelo optenemos la ecuación:

ventas = 2.938889 + 0.045765 * tv + 0.188530 * radio + -0.001037 * periodico

Tras optener los coeficientes podemos concluir que los que aportan a modelo son los de la variable tv y radio ya que estos son positivos, en cambio el de periodico al ser negativo mas bien esta restando al modelo.

#3
```{r}
mod2 <- lm(ventasdb$ventas ~ ventasdb$tv+ventasdb$radio)
mod2
```
Tras generar el modelo optenemos la ecuación:

ventas = 2.92110 + 0.04575 * tv + 0.18799 * radio

En este caso los coeficientes muestran que ambos son significativos, sin embargo el de tv es muy poco ya que es muy cercano al valor 0.

#4
```{r}

mod3 <- lm(ventasdb$ventas ~ ventasdb$tv + ventasdb$radio + (ventasdb$tv*ventasdb$radio))
mod3
```
Tras generar el modelo optenemos la ecuación:

ventas = 6.750220 + 0.019101 * tv + 0.028860 * radio + 0.001086(tv*radio)

Tras optener los resultados podemos ver que todos los coeficientes obtenidos son significativos ya que todos son positivos, siendo el menos significativo de todos el de tv * radio ya que es el mas cercano a 0

**Seleccionando el mejor modelo**

```{r}
## Cálculo del coeficiente de determinación mod0
cd0 <- summary(lm(mod0))$r.squared

## Cálculo del coeficiente de correlación mod0
cc0 <- sqrt(summary(mod0)$r.squared)

## Cálculo del coeficiente de determinación mod1
cd1 <- summary(lm(mod1))$r.squared

## Cálculo del coeficiente de correlación mod1
cc1 <- sqrt(summary(mod1)$r.squared)

## Cálculo del coeficiente de determinación mod2
cd2 <- summary(lm(mod2))$r.squared
cd2

## Cálculo del coeficiente de correlación mod2
cc2 <- sqrt(summary(mod2)$r.squared)
cc2

## Cálculo del coeficiente de determinación mod3
cd3 <- summary(lm(mod3))$r.squared

## Cálculo del coeficiente de correlación mod3
cc3 <- sqrt(summary(mod3)$r.squared)
```

#1
| Ecuación del modelo| Coeficiente de correlación| Coeficiente de determinación|
|:--|:--|:--|
| ventas = 7.03259 + 0.04754 * tv|`r cc0` | `r cd0`|
| ventas = 2.938889 + 0.045765 * tv + 0.188530 * radio + -0.001037 * periodico| `r cc1`| `r cd1`|
| ventas = 2.92110 + 0.04575 * tv + 0.18799 * radio| `r cc2`| `r cd2`|
| ventas = 6.750220 + 0.019101 * tv + 0.028860 * radio + 0.001086(tv*radio)| `r cc3`| `r cd3`|

#2
Se tiene que para el modelo mod2 $R =$ `r cc2`, esto significa que la correlación lineal entre las ventas y tv, radio es positiva y moderada. Por otra parte, se tiene que $R^{2} =$ `r cd2`, de esto se interpreta que el 94.72% de variación en las venta se debe a la tv, radio y el restante 7.28% es por otros factores.

#3
```{r}
AICctab(mod0, mod1, mod2, mod3, base = T, delta = T, sort = T, weights = T, nobs = ncol(ventasdb))

```
Como podemos ver tras ejecutar la funcion el mejor modelo corresponde al mod3 con un puntaje de 490.3, luego mod1 con 722.4 en tercer lugar mod0 con 1068.1 y por ultimo mod2 que tiene un Inf.

#4
Como primer paso creamos los Explain Model
```{r}
exp_lm0 <- explain(mod0, data = ventasdb, label = "lm1", y = ventasdb$ventas)
exp_lm2 <- explain(mod2, data = ventasdb, label = "lm2", y = ventasdb$ventas)
exp_lm3 <- explain(mod3, data = ventasdb, label = "lm3", y = ventasdb$ventas)
```

Como segundo paso creamos los Performance Model
```{r}
lm0 <- model_performance(exp_lm0)
lm2 <- model_performance(exp_lm2)
lm3 <- model_performance(exp_lm3)
```

Por ultimo graficamos los modelos
```{r}
plot(lm0,lm2, lm3)
```
Como podemos ver en el gráfico el mejor modelo el el mod3 ya que presenta la curva mas baja de la grafica, como segundo mejor modelo el mod2 y como peor modelo el mod1, este criterio tiene sentido ya que ......... terminar

#5
Análisis de varianza
```{r}
anova(mod0,mod1, mod2, mod3)
```


# VI Parte: Modelos de regresión no lineal

## Caso 7:

Para esta sección se van a generar y analizar dos modelos de RNLS usando los datos de bones de la base de datos jaws, la cual contiene información sobre la longitud de la mandíbula de los venados, según la edad.

### 1. Cargar los datos del archivo de texto.

```{r}
jaws <- read.table("jaws.txt", header=T)
```

### 2. Gráfico de dispersión de los datos.

```{r}
ggplot(jaws, aes(x = age, y = bone)) + geom_point()
```

### 3. Generar modelo RNLS

Para esta parte se generará un modelo RNLS de la forma $y=a(1- e^{-c x })$, para ello se hará uso de la función nlm() del paquete stats y se usarán como valores iniciales a = 120 y c = 0.064.

```{r}
modelo1 <- nls(bone~a*(1-exp(-c*age)), data = jaws, start = list(a=120, c=0.064))
modelo1
```

### Gráfico del modelo.

Ahora se procederá a realizar un gráfico del modelo anterior junto al de dispersión:

```{r}
xo <- seq(from = min(jaws$age) - 0.2, to = max(jaws$age) + 0.2, by = 0.01)
yo <- 120 * (1 - exp(-0.064 - xo))

# Graficamos dispersión y el modelo de ajuste en un mismo plot
plot(jaws$age, jaws$bone, main = "Modelo de RNLS f(x)=a(1- e^{-c x })", col = "darkblue", lwd = 2)
lines(xo, yo, type = "l")
```

### 5. Segundo modelo (selección del modelo).

Para este punto se hará un segundo modelo. Considerando que la gráfica tiene una asintota alrededor de 120 en el eje X y que parece tener también una menor que 0 en el eje Y (ya que ya hay un punto que toca 0) se decidirá por utilizar el modelo el modelo hiperbólico ya que este contiene asintotas en ambos ejes y permite más libertad en el posicionamiento de estas.

### 6. Linealización del segundo modelo.

En está parte se hara una estimación de los parámetros $\alpha$ y $\beta$ a través de un proceso de lineación a partir de un modelo RLS, para esto se hara uso una vez más de la función lm haciendo la sistitución de variables respectiva, que es la siguiente:

$X_2 = \frac{1}{X}$ y $Y_2 = \frac{1}{Y}$

Teniendo en cuenta esto último se procede a realizar el RLS:

```{r}
X2 <- 1/jaws$age
Y2 <- 1/jaws$bone
datoslm <- cbind(X2, Y2)
datoslm.df <- as.data.frame(datoslm)

## Se eliminan los infinitos del caso 0/0
datoslm.df <- datoslm.df[!is.infinite(rowSums(datoslm.df)),]
modelolm <- lm(Y2 ~ X2, data = datoslm.df)
modelolm
```

Se tiene que:

$\alpha = 0.00523$ y $\beta = 0.10339$

### 7. Creación del segundo RNLS.

A partir de la estimación anterior de $\alpha$ y $\beta$ se procederá a utilizar la función nls para generar un segundo modelo RNLS utilizando $\alpha$ y $\beta$ como los valores iniciales

```{r}
modelo2 <- nls(bone~(age)/(a*age+b), data = jaws, start = list(a=0.00523, b=0.10339))
modelo2
```

Finalmente se tiene que la ecuación de RNLS es:

$y = \frac{x}{0.007261x+0.053404}$

### 8. Gráfico del segundo modelo RNLS.

En este punto se procede a realizar un gráfico del modelo generado en el paso anterior de la siguiente manera:

```{r}
xo <- seq(from = min(jaws$age) - 0.2, to = max(jaws$age) + 0.2, by = 0.01)
yo <- xo / (0.007261 * xo + 0.053404)

# Graficamos dispersión y el modelo de ajuste en un mismo plot
plot(jaws$age, jaws$bone, main = "Modelo de RNLS f(x)=a(1- e^{-c x })", col = "darkblue", lwd = 2)
lines(xo, yo, type = "l")
```

### 9. Comparación de ambos modelos.

En este punto se comparán ambos modelos con el fin de cuantificar cual es mejor, para esto se hara uso de la función anova del paquete stats de R.

```{r}
anova(modelo1, modelo2)
```

En este caso bajo el criterio de análisis de varianzas el modelo 1 resulto ser el mejor ya que tiene un RSS menor. Sin embargo, esto parece no coincidir con la gráficas ya que parece ser que la gráfica del modelo 2 se ajusta mejor a los datos en comparación a la del modelo 1.
